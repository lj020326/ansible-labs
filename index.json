[
{
	"uri": "https://lj020326.github.io/ansible-getting-started/",
	"title": "Ansible Getting Started",
	"tags": [],
	"description": "",
	"content": "Ansible Getting Started   Exercise 1 - Check the Prerequisites\n  Exercise 2 - Running ad hoc Commands\n  Exercise 3 - Writing Your First Playbook\n  Exercise 4 - Using Variables\n  Exercise 5 - Conditionals, Handlers and Loops\n  Exercise 6 - Templates\n  Exercise 7 - Bonus Labs\n  "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/1-intro/",
	"title": "Ansible Tower Advanced",
	"tags": [],
	"description": "",
	"content": "About this Lab You have already used Ansible Automation quite a bit and have started to look into Tower? Or you are already using Tower? Cool. We prepared this lab to give a hands-on introduction to some of the more advanced features of Tower. You’ll learn about:\n  Using command line tools to manage Ansible Tower\n  Ansible Tower clustering\n  Working with Instance Groups\n  Using isolated nodes to manage remote locations\n  Ways to provide inventories (importing inventory, dynamic inventory)\n  The Smart Inventory feature\n  Optional: How to structure Ansible content in Git repos\n  Optional: How to work with the Tower API\n  So little time and so much to do… To be honest we got carried away slightly while trying to press all these cool features into a two-hours lab session. We decided to flag the last two chapters as \u0026ldquo;optional\u0026rdquo; instead of taking them out. If you find the time to run them, cool! If not, the lab guide will stay where it is, feel free to go through these lab tasks later (you don’t need a Tower cluster for this).\n Want to Use this Lab after AnsibleFest? Definitely, the Markdown sources are available here:\nhttps://github.com/lj020326/ansible-labs/tree/master/content/ansible-tower-advanced\nYour Ansible Tower Lab Environment In this lab you work in a pre-configured lab environment. You will have access to the following hosts:\n   Role URL for External Access (if applicable) Hostname Internal     Ansible Tower Node 1 student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com ansible-1   Ansible Tower Node 2  ansible-2   Ansible Tower Node 3  ansible-3   Visual Code Web UI student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com    Ansible Tower Database Host  ansible-4   Managed RHEL8 Host 1  node1   Managed RHEL8 Host 2  node2   Ansible Tower Isolated Node  isonode   Managed Remote Host 1  remotenode    The lab environments in this session have a \u0026lt;LABID\u0026gt; and are separated by numbered student\u0026lt;N\u0026gt; accounts. You will be able to access the hosts using the external hostnames. Internally the hosts have different names as shown above. Follow the instructions given by the lab facilitators to receive the values for student\u0026lt;N\u0026gt; and \u0026lt;LABID\u0026gt;!\n Ansible Tower has already been installed and licensed for you, the web UI will be reachable over HTTP/HTTPS.\n Wherever you see the placeholder VERY_SECRET_PASSWORD in the following pages, use instead the specific password provided to you on the lab page. In general, whenever you need a password, even without the placeholder explicitly written, it\u0026rsquo;s the same one.\n As you can see the lab environment is pretty extensive. You basically have:\n  A three-node Tower cluster with a separate DB host, accessed via SSH or web UI\n  Two managed RHEL 8 hosts\n  And to mimic a remote site with isolated nodes:\n  One RHEL 8 host that acts as an isolated Tower node that can be reached via SSH from the Tower cluster nodes.\n  One RHEL 8 host which acts as a remote managed node that can only be reached from/through the isolated node.\n  Access to the isolated node and the managed hosts is actually not restricted in the lab environment. Just imagine filtered, DMZ-like access rules for educational purposes… ;-)\n Working the Lab Some hints to get you started:\n  Don’t type everything manually, use copy \u0026amp; paste from the browser when appropriate. But don’t stop to think and understand… ;-)\n  To edit files or open a terminal window, we provide code-server, basically the great VSCode Editor running in your browser. It\u0026rsquo;s running on the first Tower node and can be accessed through the URL https://student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com\n  Commands you are supposed to run are shown with or without the expected output, whatever makes more sense in the context.\n The command line can wrap on the HTML page from time to time. Therefore the output is often separated from the command line for better readability by an empty line. Anyway, the line you should actually run should be recognizable by the prompt. :-)\n Accessing your Lab Environment You\u0026rsquo;ll get the access information for your lab (URL\u0026rsquo;s, password) from a landing page. Getting access to this page depends on how you are consuming the lab:\n  If you deployed from RHPDS, you\u0026rsquo;ll receive an email with the landing page URL\n  If you attend this lab at an event, your lab facilitator will lead you to the landing page\n  Either way you\u0026rsquo;ll get an URL similar to this: http://\u0026lt;LABID\u0026gt;.open.redhat.com\nYour main points of contact with the lab are the Ansible Tower web UI\u0026rsquo;s and code-server, providing a VSCode-experience in your browser. You\u0026rsquo;ll use code-server to:\n  open virtual terminals\n  edit files\n  Now open code-server using the link from the lab landing page or this link in your browser by replacing \u0026lt;N\u0026gt; by your student number and the \u0026lt;LABID\u0026gt;:\nhttps://student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com Use the password provided on the landing page to login into the code-server web UI, you can close the Welcome tab. Now open a new terminal by heading to the menu item Terminal at the top of the page and select New Terminal. A new section will appear in the lower half of the screen and you will be greeted with a prompt:\nIf unsure about the usage, read the Visual Studio Code Server introduction, to learn more about how to create and edit files, and to work with the Terminal.\nCongrats, you now have a shell terminal on your Ansible Tower node 1. From here you run commands or access the other hosts in your lab environment if the lab task requires it.\n"
},
{
	"uri": "https://lj020326.github.io/ansible-getting-started/1-setup/",
	"title": "Check the Prerequisites",
	"tags": [],
	"description": "",
	"content": "Your Lab Environment In this lab you work in a pre-configured lab environment. You will have access to the following hosts:\n   Role Inventory name     Ansible Control Host ansible   Managed Host 1 node1   Managed Host 2 node2   Managed Host 3 node3    The lab environments in this session have a \u0026lt;LABID\u0026gt; and are separated by numbered student\u0026lt;N\u0026gt; accounts. Follow the instructions given by the lab facilitators to receive the values for student\u0026lt;N\u0026gt; and \u0026lt;LABID\u0026gt;!\n On the lab landing page you\u0026rsquo;ll find the URLs you need to access complete with student number and lab ID already filled in.\n Accessing your Lab Environment Your main points of contact with the lab is code-server, providing a VSCode-experience in your browser.\nNow open code-server using the VS Code access link from the lab landing page or use this link in your browser by replacing \u0026lt;N\u0026gt; by your student number and the \u0026lt;LABID\u0026gt;:\nhttps://student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com  Use the password provided on the lab landing page to login into the code-server web UI, you can close the Welcome tab. Now open a new terminal by heading to the menu item Terminal at the top of the page and select New Terminal. A new section will appear in the lower half of the screen and you will be greeted with a prompt:\nIf unsure how to use code-server, read the Visual Studio Code Server introduction, to learn more about how to create and edit files, and to work with the Terminal.\nCongrats, you now have a shell terminal on your Ansible control node. From here you run commands or access the other hosts in your lab environment if the lab task requires it.\nNow in the terminal become root:\n[student@ansible-1 ~]$ sudo -i  Most prerequisite tasks have already been done for you:\n  Ansible software is installed\n  sudo has been configured on the managed hosts to run commands that require root privileges.\n  Check Ansible has been installed correctly (your actual Ansible version might differ):\n[root@ansible-1 ~]# ansible --version ansible 2.9.6 [...]  Ansible is keeping configuration management simple. Ansible requires no database or running daemons and can run easily on a laptop. On the managed hosts it needs no running agent.\n Log out of the root account again:\n[root@ansible-1 ~]# exit logout  In all subsequent exercises you should work as the student\u0026lt;N\u0026gt; user on the control node if not explicitly told differently.\n Working the Labs You might have guessed by now this lab is pretty command line-centric…​ :-)\nDon’t type everything manually, use copy \u0026amp; paste from the browser when appropriate. But do still take time to think and understand.\nIn the lab guide commands you are supposed to run are shown with or without the expected output, whatever makes more sense in the context.\n Challenge Labs You will soon discover that many chapters in this lab guide come with a \u0026ldquo;Challenge Lab\u0026rdquo; section. These labs are meant to give you a small task to solve using what you have learned so far. The solution of a challenge task is shown beneath the task in a fold-out.\n"
},
{
	"uri": "https://lj020326.github.io/ansible-collections/1-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "This chapter will introduce you to your lab environment and introduce you to the importance of Ansible Collections, what they are and where existing collections can be found and consumed.\nYour Lab Environment In this lab you work in a pre-configured lab environment. You will have access to the following hosts:\n   Role URL for External Access (if applicable) Hostname Internal     Ansible Tower student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com ansible-1   Visual Code Web UI student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com    Managed RHEL8 Host 1  node1   Managed RHEL8 Host 2  node2   Managed RHEL8 Host 3  node3    The lab environments in this session have a \u0026lt;LABID\u0026gt; and are separated by numbered student\u0026lt;N\u0026gt; accounts. Follow the instructions given by the lab facilitators to receive the values for student\u0026lt;N\u0026gt; and \u0026lt;LABID\u0026gt;!\n On the lab landing page you\u0026rsquo;ll find the URLs you need to access complete with student number and lab ID already filled in.\n Accessing your Lab Environment Your main points of contact with the lab is code-server, providing a VSCode-experience in your browser.\nNow open code-server using the VS Code access link from the lab landing page or use this link in your browser by replacing \u0026lt;N\u0026gt; by your student number and the \u0026lt;LABID\u0026gt;:\nhttps://student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com Use the password provided on the lab landing page to login into the code-server web UI, you can close the Welcome tab. Now open a new terminal by heading to the menu item Terminal at the top of the page and select New Terminal. A new section will appear in the lower half of the screen and you will be greeted with a prompt:\nIf unsure how to use code-server, read the Visual Studio Code Server introduction, to learn more about how to create and edit files, and to work with the Terminal.\nCongrats, you now have a shell terminal on your Ansible control node. From here you run commands or access the other hosts in your lab environment if the lab task requires it.\nNow in the terminal become root:\n[student@ansible-1 ~]$ sudo -i  Most prerequisite tasks have already been done for you:\n  Ansible software is installed\n  sudo has been configured on the managed hosts to run commands that require root privileges.\n  Check Ansible has been installed correctly (your actual Ansible version might differ):\n[ansible-1 ~]# ansible --version ansible 2.9.13 [...]  Log out of the root account again:\n[ansible-1 ~]# exit logout  In all subsequent exercises you should work as the student\u0026lt;N\u0026gt; user on the control node if not explicitly told differently.\n What are Collections and why should I care? Ansible Collections are a new distribution format for Ansible content that can include playbooks, roles, modules, and plugins. Modules are moved from the core Ansible repository into collections living in repositories outside of the core repository. This change in the content delivery process will allow Ansible to keep up the tremendous success and, coming with it, growth in content.\n Before collections, module creators had to wait for their modules to be included in an upcoming Ansible release or had to add them to roles, which made consumption and management more difficult. By distributing modules packaged in Ansible Content Collections along with roles, documentation and even playbooks, content creators are now able to move as fast or conservative as the technology they manage demands.  Example: A public cloud provider could make new functionality of an existing service available, that could be rolled out along with the ability to automate the new functionality with Ansible. With Ansible Collections the author doesn\u0026rsquo;t have to wait for the next Ansible release and can instead roll out the new content independently. Prior to Ansible Collections the author had to wait for the next Ansible release.\nFor Ansible users, the benefit is that updated content can continuously be made available. Managing content this way also becomes easier as modules, plugins, roles, and docs that belong together are packaged together and versioned.\nFully Qualified Collection Name Ansible Collection names are a combination of two components. The first part is the name of the author who wrote and maintains the Ansible Collection. The second part is the name of the Ansible Collection. This allows one author to have multiple Collections. It also allows multiple authors to have Ansible Collections with the same name.\n\u0026lt;author\u0026gt;.\u0026lt;collection\u0026gt;  These are examples for Ansible Collection names:\n  ansible.posix\n  geerlingguy.k8s\n  theforeman.foreman\n  To identify a specific module in an Ansible Collection, we add the name of it as the third part:\n\u0026lt;author\u0026gt;.\u0026lt;collection\u0026gt;.\u0026lt;module\u0026gt;  Valid examples for a fully qualified Ansible Collection Name:\n  ansible.posix.selinux\n  geerlingguy.k8s.kubernetes\n  theforeman.foreman.user\n  Understand Collections Lookup Ansible Collections use a simple method to define collection namespaces. If your playbook loads collections using the collections key and one or more roles, then the roles will not inherit the collections set by the playbook.\nThis leads to the main topic of this exercise: roles have an independent collection loading method based on the role\u0026rsquo;s metadata. To control collections search for the tasks inside the role, users can choose between two approaches:\n  Approach 1: Pass a list of collections in the collections field inside the meta/main.yml file within the role. This will ensure that the collections list searched by the role will have higher priority than the collections list in the playbook. Ansible will use the collections list defined inside the role even if the playbook that calls the role defines different collections in a separate collections keyword entry.\n# myrole/meta/main.yml collections: - my_namespace.first_collection - my_namespace.second_collection - other_namespace.other_collection   Approach 2: Use the collection fully qualified collection name (FQCN) directly from a task in the role. In this way the collection will always be called with its unique FQCN, and override any other lookup in the playbook\n- name: Create an EC2 instance using collection by FQCN amazon.aws.ec2: key_name: mykey instance_type: t2.micro image: ami-123456 wait: yes group: webserver count: 3 vpc_subnet_id: subnet-29e63245 assign_public_ip: yes   Roles defined within a collection always implicitly search their own collection first, so there is no need to use the collections keyword in the role metadata to access modules, plugins, or other roles.\nIn the following chapters of this lab you will learn how collections work and see different examples to see how it works.\nSince the Ansible Collection lookup could can deliver unexpected results, it is best practice to always use the fully qualified collection name.\n "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-getting-started/1-intro/",
	"title": "Introduction to Tower",
	"tags": [],
	"description": "",
	"content": "Why Ansible Tower? Ansible Tower is a web-based UI that provides an enterprise solution for IT automation. It\n  has a user-friendly dashboard.\n  complements Ansible, adding automation, visual management, and monitoring capabilities.\n  provides user access control to administrators.\n  graphically manages or synchronizes inventories with a wide variety of sources.\n  has a RESTful API.\n  And much more\u0026hellip;\n  Your Ansible Tower Lab Environment In this lab you work in a pre-configured lab environment. You will have access to the following hosts:\n   Role URL for External Access (if applicable) Hostname Internal     Ansible Tower student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com ansible-1   Visual Code Web UI student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com    Managed RHEL8 Host 1  node1   Managed RHEL8 Host 2  node2   Managed RHEL8 Host 3  node3    The lab environments in this session have a \u0026lt;LABID\u0026gt; and are separated by numbered student\u0026lt;N\u0026gt; accounts. You will be able to access the hosts using the external hostnames. Internally the hosts have different names as shown above. Follow the instructions given by the lab facilitators to receive the values for student\u0026lt;N\u0026gt; and \u0026lt;LABID\u0026gt;!\n Ansible Tower has already been installed and licensed for you, the web UI will be reachable over HTTP/HTTPS.\n Wherever you see the placeholder VERY_SECRET_PASSWORD in the following pages, use instead the specific password provided to you on the lab page. In general, whenever you need a password, even without the placeholder explicitly written, it\u0026rsquo;s the same one.\n Working the Lab Some hints to get you started:\n  Don’t type everything manually, use copy \u0026amp; paste from the browser when appropriate. But don’t stop to think and understand… ;-)\n  To edit files or open a terminal window, we provide code-server, basically the great VSCode Editor running in your browser. It\u0026rsquo;s running on the first Tower node and can be accessed through the URL https://student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com\n  Commands you are supposed to run are shown with or without the expected output, whatever makes more sense in the context.\n The command line can wrap on the HTML page from time to time. Therefore the output is often separated from the command line for better readability by an empty line. Anyway, the line you should actually run should be recognizable by the prompt. :-)\n Accessing your Lab Environment You\u0026rsquo;ll get the access information for your lab (URL\u0026rsquo;s, password) from a landing page. Getting access to this page depends on how you are consuming the lab:\n  If you deployed from RHPDS, you\u0026rsquo;ll receive an email with the landing page URL\n  If you attend this lab at an event, your lab facilitator will lead you to the landing page\n  Either way you\u0026rsquo;ll get an URL similar to this: http://\u0026lt;LABID\u0026gt;.open.redhat.com\nYour main points of contact with the lab are the Ansible Tower web UI\u0026rsquo;s and code-server, providing a VSCode-experience in your browser. You\u0026rsquo;ll use code-server to:\n  open virtual terminals\n  edit files\n  Now open code-server using the link from the lab landing page or this link in your browser by replacing \u0026lt;N\u0026gt; by your student number and the \u0026lt;LABID\u0026gt;:\nhttps://student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com Use the password provided on the landing page to login into the code-server web UI, you can close the Welcome tab. Now open a new terminal by heading to the menu item Terminal at the top of the page and select New Terminal. A new section will appear in the lower half of the screen and you will be greeted with a prompt:\nIf unsure about the usage, read the Visual Studio Code Server introduction, to learn more about how to create and edit files, and to work with the Terminal.\nCongrats, you now have a shell terminal on your Ansible Tower node 1. From here you run commands or access the other hosts in your lab environment if the lab task requires it.\nDashboard Let\u0026rsquo;s have a first look at Tower: Point your browser to the URL you were given on the lab landing page, similar to https://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com (replace \u0026lt;N\u0026gt; with your student number and \u0026lt;LABID\u0026gt; with the ID of this lab) and log in as admin. You can find the password again on the lab landing page.\nThe web UI of Ansible Tower greets you with a dashboard giving an overview of your automation including:\n  recent job activity\n  the number of managed hosts\n  quick pointers to lists of hosts with problems.\n  The dashboard also displays real time data about the execution of tasks completed in playbooks.\nConcepts Before we dive further into using Ansible Tower for your automation, you should get familiar with some concepts and naming conventions.\nProjects Projects are logical collections of Ansible playbooks in Ansible Tower. These playbooks either reside on the Ansible Tower instance, or in a source code version control system supported by Tower.\nInventories An Inventory is a collection of hosts against which jobs may be launched, the same as an Ansible inventory file. Inventories are divided into groups and these groups contain the actual hosts. Groups may be populated manually, by entering host names into Tower, from one of Ansible Tower’s supported cloud providers or through dynamic inventory scripts.\nCredentials Credentials are utilized by Tower for authentication when launching Jobs against machines, synchronizing with inventory sources, and importing project content from a version control system. Credential configuration can be found in the Settings.\nTower credentials are imported and stored encrypted in Tower, and are not retrievable in plain text on the command line by any user. You can grant users and teams the ability to use these credentials, without actually exposing the credential to the user.\nTemplates A job template is a definition and set of parameters for running an Ansible job. Job templates are useful to execute the same job many times. Job templates also encourage the reuse of Ansible playbook content and collaboration between teams. To execute a job, Tower requires that you first create a job template.\nJobs A job is basically an instance of Tower launching an Ansible playbook against an inventory of hosts.\n"
},
{
	"uri": "https://lj020326.github.io/ansible-tower-getting-started/",
	"title": "Ansible Tower Getting Started",
	"tags": [],
	"description": "",
	"content": "Ansible Tower Getting Started   Exercise 1 - Introduction to Tower\n  Exercise 2 - Inventories, credentials and ad hoc commands\n  Exercise 3 - Projects \u0026amp; job templates\n  Exercise 4 - Surveys\n  Exercise 5 - Role-based access control\n  Exercise 6 - Workflows\n  Exercise 7 - Wrap up\n  "
},
{
	"uri": "https://lj020326.github.io/ansible-collections/2-using-collections-from-playbooks/",
	"title": "Collections from Playbook",
	"tags": [],
	"description": "",
	"content": "For the following exercise, we will use a collection written by the Ansible Core Team. The name of the author is therefore \u0026ldquo;ansible\u0026rdquo;. You can find a list of all modules and collections written by the Ansible Core Team on Ansible Galaxy. Head over there and have a good look around!\nAs you can see they maintain several collections and roles. One of their collections is called \u0026ldquo;posix\u0026rdquo; and we can find the documentation and additional details on the Ansible Galaxy POSIX Collection page.\nOne of the modules provided by this collection allows us to manage SELinux settings. The fully qualified collection name for this module is therefore ansible.posix.selinux.\nYou can find more details about using collections in the Ansible Documentation.\nInstall the Ansible Collection The ansible.posix.selinux module which we want to use for this exercise, is part of the ansible.posix collection. We have to install this collection first, before we can use its modules. The ansible-galaxy command line tool can be used to automate the installation. It is preconfigured to search for roles and collections on Ansible Galaxy so we can just specify the collection name and it will take care of the rest.\nBring up a browser window with code-server and open a terminal. In the terminal run:\n[student@ansible-1 ~]$ ansible-galaxy collection install ansible.posix  This will install the collection on your system, only if it wasn\u0026rsquo;t installed before. To force the installation, for example to make sure you\u0026rsquo;re on the latest version, you can add the force switch -f.\n[student@ansible-1 ~]$ ansible-galaxy collection install -f ansible.posix  This will always download and install the latest version, even if it was already up to date. Ansible Collections can have dependencies for other Ansible Collections as well - if you want to make sure those dependencies are refreshed as well, you can use the --force-with-deps switch.\nBy default the installation is stored in your local ~/.ansible directory. This can be overwritten by using the -p /path/to/collection switch. Keep in mind though that ansible-playbook will only use this directory, if you change your ansible.cfg accordingly. To check your current configuration, you can dump your configuration and search for collection.\n[student@ansible-1 ~]$ ansible-config dump | grep -i collection COLLECTIONS_PATHS(default) = [\u0026#39;/home/student\u0026lt;N\u0026gt;/.ansible/collections\u0026#39;, \u0026#39;/usr/share/ansible/collections\u0026#39;] Browse the Documentation The ansible-doc command only searches the system directories for documentation. You can still use it though to read up on modules you installed from Ansible Collections by using the fully qualified collection name.\nLet\u0026rsquo;s have a look at the module documentation for the selinux module of the ansible.posix collection, which we are going to use in the next part of the exercise:\n[student@ansible-1 ~]$ ansible-doc ansible.posix.selinux \u0026gt; SELINUX (/home/student\u0026lt;N\u0026gt;/.ansible/collections/ansible_collections/ansible/posix/plugins/modules/selinux.py)  Note the start of the output, you can see the location of the module. For educational purposes run the ansible-doc again, but this time not specifying the collection:\n[student@ansible-1 ~]$ ansible-doc selinux \u0026gt; SELINUX (/usr/lib/python3.6/site-packages/ansible/modules/system/selinux.py)  You can see how the command this time pulled the documentation for the module that was installed with Ansible.\nDepending on your screen resolution you might have to press q to leave the documentation viewer.\n Write an Ansible Playbook We want to use the SELinux module to make sure it is configured in enforcing mode. SELinux is a kernel feature which brings extra security to our Linux system and it is highly recommended to always keep it enabled and in enforcing mode. If you\u0026rsquo;re new to SELinux, there is a nice article on What is SELinux to get you started.\nLet\u0026rsquo;s write a simple playbook which enables SELinux and sets it to enforcing mode on the local machine. In this lab you can use the visual code-server editor or run an editor of your choice from the terminal. Create the Playbook enforce-selinux.yml with the following content:\n--- - name: set SELinux to enforcing hosts: localhost become: yes tasks: - name: set SElinux to enforcing ansible.posix.selinux: policy: targeted state: enforcing Make sure you save the playbook as enforce-selinux.yml in your student users home directory.\nPay special attention to the module name. Typically you would see something like selinux, but since we are using a module provided by an Ansible Collection, we have to specify the fully qualified collection name.\n Test the playbook Noe let\u0026rsquo;s run the Playbook and see what happens:\n[student@ansible-1 ~]$ ansible-playbook enforce-selinux.yml  You should see output like this:\n[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all' PLAY [set SELinux to enforcing] *********************************************************************************** TASK [Gathering Facts] ******************************************************************************************** ok: [localhost] TASK [set SElinux to enforcing] *********************************************************************************** ok: [localhost] PLAY RECAP ******************************************************************************************************** localhost : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0  If SELinux was not set to enforcing mode before, you might see \u0026ldquo;changed\u0026rdquo; instead of \u0026ldquo;ok\u0026rdquo;. If it did say \u0026ldquo;changed\u0026rdquo; and you run it a second time, you should now see \u0026ldquo;ok\u0026rdquo; - the magic of Ansible idempotency.\nSimplify the namespace If you use many modules from Ansible Collections in your Playbook, the \u0026lt;author\u0026gt;.\u0026lt;collection\u0026gt; prefix can become quite annoying and reading your Playbook can become harder as well.\nYou can use the collections keyword to skip defining the namespace with every task. In your terminal edit the Playbook enforce-selinux.yml to look like this, basically adding the collections: section and changing the module name from FQCN to the simple module name:\n--- - name: set SELinux to enforcing hosts: localhost become: yes collections: - ansible.posix tasks: - name: set SElinux to enforcing selinux: policy: targeted state: enforcing  Although the syntax looks similar to how you specify roles, this works different. They keyword roles will execute the tasks/main.yml in each role. The collections keyword is merely a shortcut so you can skip the author and namespace every time you use a module in a task.\n Test the change Now run the Playbook again, you shouldn\u0026rsquo;t see any difference in the output. As explained before, the collections keyword only simplifies writing your Playbook!\nWe are explaining the collections keyword here for completeness. It is however recommended to always use the fully qualified collection name. The internal lookup can deliver unexpected results if there are many overlapping or overriding module names, which can be avoided by always using the full name. Since most modern code editors provide auto completion, it\u0026rsquo;s not too much of an issue when typing the code either.\n "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/2-clustering/",
	"title": "Introduction to Ansible Tower Clustering",
	"tags": [],
	"description": "",
	"content": "With version 3.1 Ansible Tower introduced clustering, replacing the redundancy solution configured with active-passive nodes. Clustering is sharing load between Tower nodes/instances. Each Tower instance is able to act as an entry point for UI and API access.\nUsing a load balancer in front of the Tower nodes is possible, but optional because an Ansible Tower cluster can be accessed via all Tower instances.\n Each instance in a Tower cluster expands the cluster’s capacity to execute jobs. Jobs can and will run anywhere rather than be directed on where to run.\nThe Appendix contains some installation considerations and an installer inventory for reference.\n Access the Tower Web UI For the first contact to your cluster open your browser and login to the Tower node 1 web UIs as:\n  user admin\n  password VERY_SECRET_PASSWORD\n  Use the pre-created URLs from the lab landing page or replace \u0026lt;LABID\u0026gt; with the session ID and \u0026lt;N\u0026gt; with your student number!\n https://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com\nJust from the web UI you wouldn’t know you’ve got a Tower cluster at your hands here. To learn more about your cluster and its state, in one of the instances web UI under ADMINISTRATION choose Instance Groups. Here you will get an overview of the cluster by instance groups. Explore the information provided, of course there is no capacity used yet and no Jobs have run.\nRight now we have only one instance group named tower. When you get more groups, from this view you will see how the instance are distributed over the groups.\nTo dig deeper click on INSTANCES to get more information about the instances allocated to a group. In the instances view you can toggle nodes off/online and adjust the number of forks (don\u0026rsquo;t do this now).\nYou’ll learn more about this later.\nAccess your Tower Cluster via Command line You can also get information about your cluster on the command line. Log in to your code-server again if you closed it by opening this URL in your browser:\nhttps://student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com\nYour VSCode session is running on your Tower node 1. Again if not still open, open a terminal by clicking Terminal-\u0026gt;New Terminal in the menu bar.\nA terminal window opens at the bottom, become root:\n[student@ansible-1 ~]$ sudo -i [root@ansible-1 ~]# In the terminal run the following command:\n Your exact hostnames will differ, of course!\n [root@ansible-1 ~]# awx-manage list_instances [tower capacity=51] ansible-1 capacity=17 version=3.7.1 heartbeat=\u0026#34;2020-08-27 09:06:21\u0026#34; ansible-2 capacity=17 version=3.7.1 heartbeat=\u0026#34;2020-08-27 09:05:58\u0026#34; ansible-3 capacity=17 version=3.7.1 heartbeat=\u0026#34;2020-08-27 09:06:00\u0026#34; So what we’ve got is a three-node Tower cluster, no surprises here. In addition the command tells us the capacity (maximum number of forks/concurrent jobs) per node and for the instance groups. Here the capacity value of 17 is allocated to any of our three nodes.\nThe awx-manage (formerly tower-manage) utility can be used to manage a lot of the more internal aspects of Tower. You can e.g. use it to clean up old data, for token and session management and for cluster management.\n "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-getting-started/2-cred/",
	"title": "Inventories, credentials and ad hoc commands",
	"tags": [],
	"description": "",
	"content": "Create an Inventory Let’s get started: The first thing we need is an inventory of your managed hosts. This is the equivalent of an inventory file in Ansible Engine. There is a lot more to it (like dynamic inventories) but let’s start with the basics.\n You should already have the web UI open, if not: Point your browser to the URL you were given, similar to https://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com (replace \u0026ldquo;\u0026lt;N\u0026gt;\u0026rdquo; and \u0026ldquo;\u0026lt;LABID\u0026gt;\u0026quot;) and log in as admin with the password given on the lab landing page.  Create the inventory:\n  In the web UI menu on the left side, go to RESOURCES → Inventories, click the button on the right side and choose Inventory.\n  NAME: Workshop Inventory\n  ORGANIZATION: Default\n  Click SAVE\n  Go back to the Inventories list, your new Workshop Inventory should show up. Open the Workshop Inventory and click the HOSTS button, the list will be empty since we have not added any hosts yet.\nSo let\u0026rsquo;s add some hosts. As mentioned in the intro you have three managed hosts in your lab environment, the names are resolved through the /etc/hosts file. The nodes are named node1, node2 and node3.\nNow add the hosts to the inventory in Tower:\n  In the inventory view of the Tower web UI click on your Workshop Inventory\n  Click on the HOSTS button (the one at the top, not the bottom one, which is read-only and shows all hosts in all inventories)\n  To the right click the button.\n  HOST NAME: node1\n  Click SAVE\n  Go back to HOSTS or use the frame below the new node frame in the UI and repeat to add node2 as a second and node3 as a third node.\n  You have now created an inventory with three managed hosts.\nMachine Credentials One of the great features of Ansible Tower is to make credentials usable to users without making them visible. To allow Tower to execute jobs on remote hosts, you must configure connection credentials.\nThis is one of the most important features of Tower: Credential Separation! Credentials are defined separately and not with the hosts or inventory settings.\n As this is an important part of your Tower setup, why not make sure that connecting to the managed nodes from Tower is working in the first place?\nTo test access to the nodes via SSH do the following:\n  In your browser bring up the terminal window in code-server (remember this runs on the Tower node)\n  From here as user ec2-user SSH into node1 or one of the other nodes and execute sudo -i.\n  For the SSH connection use the node password from the inventory file, sudo -i works without password.\n  [ansible-1 ~]$ ssh ec2-user@node1 [ec2-user@node1 ~]$ sudo -i [root@node1 ~]# exit [ec2-user@node1 ~]$ exit What does this mean?\n  Tower user student\u0026lt;N\u0026gt; can connect to the managed hosts with SSH key authentication as user ec2-user.\n  User ec2-user can execute commands on the managed hosts as root with sudo.\n  Configure Machine Credentials Now we will configure the credentials to access our managed hosts from Tower. In the RESOURCES menu choose Credentials. Now:\nClick the button to add new credentials\n  NAME: Workshop Credentials\n  ORGANIZATION: Click on the magnifying glass, pick Default and click SELECT\n  CREDENTIAL TYPE: Click on the magnifying glass, pick Machine as type and click SELECT (you will have to use the search or cycle through the types to find it).\n  USERNAME: ec2-user\n  PRIVILEGE ESCALATION METHOD: sudo\n  Whenever you see a magnifying glass icon next to an input field, clicking it will open a list to choose from.\n As we are using SSH key authentication, you have to provide an SSH private key that can be used to access the hosts. You could also configure password authentication here.\nBring up your code-server terminal on Tower, and cat the SSH private key:\n[ansible-1 ~]$ cat .ssh/aws-private.pem -----BEGIN RSA PRIVATE KEY----- MIIEpAIBAAKCAQEA2nnL3m5sKvoSy37OZ8DQCTjTIPVmCJt/M02KgDt53+baYAFu1TIkC3Yk+HK1 [...] -----END RSA PRIVATE KEY-----   Copy the complete private key (including \u0026ldquo;BEGIN\u0026rdquo; and \u0026ldquo;END\u0026rdquo; lines) and paste it into the SSH PRIVATE KEY field in the web UI.\n  Click SAVE\n  Go back to the RESOURCES -\u0026gt; Credentials -\u0026gt; Workshop Credentials and note that the SSH key is not visible.\nYou have now setup credentials for Ansible to access your managed hosts.\nRun Ad Hoc Commands As you’ve probably done with Ansible before you can run ad hoc commands from Tower as well.\n  In the web UI go to RESOURCES → Inventories → Workshop Inventory\n  Click the HOSTS button to change into the hosts view and select the three hosts by checking the boxes to the left of the host entries.\n  Click RUN COMMANDS. In the next screen you have to specify the ad hoc command:\n  As MODULE choose ping\n  For MACHINE CREDENTIAL click the magnifying glass icon and select Workshop Credentials.\n  Click LAUNCH, and watch the output.\n    The simple ping module doesn’t need options. For other modules you need to supply the command to run as an argument. Try the command module to find the user ID of the executing user using an ad hoc command.\n  MODULE: command\n  ARGUMENTS: id\n  After choosing the module to run, Tower will provide a link to the docs page for the module when clicking the question mark next to \u0026ldquo;Arguments\u0026rdquo;. This is handy, give it a try.\n -- How about trying to get some more private information from the system? Try to print out /etc/shadow.\n  MODULE: command\n  ARGUMENTS: cat /etc/shadow\n  Expect an error!\n Oops, the last one didn’t went well, all red.\nRe-run the last ad hoc command but this time tick the ENABLE PRIVILEGE ESCALATION box.\nAs you see, this time it worked. For tasks that have to run as root you need to escalate the privileges. This is the same as the become: yes you’ve probably used often in your Ansible Playbooks.\nChallenge Lab: Ad Hoc Commands Okay, a small challenge: Run an ad hoc to make sure the package \u0026ldquo;tmux\u0026rdquo; is installed on all hosts. If unsure, consult the documentation either via the web UI as shown above or by running ansible-doc yum on your Tower control host.\nClick here for Solution    MODULE: yum ARGUMENTS: name=tmux Tick ENABLE PRIVILEGE ESCALATION    The yellow output of the command indicates Ansible has actually done something (here it needed to install the package). If you run the ad hoc command a second time, the output will be green and inform you that the package was already installed. So yellow in Ansible doesn’t mean \u0026ldquo;be careful\u0026rdquo;…​ ;-).\n Try to click one of the output lines in the window showing the job output. A small window with a lot of information about the job like module args will open. Have a look and close it again.\n "
},
{
	"uri": "https://lj020326.github.io/ansible-getting-started/2-adhoc/",
	"title": "Running ad hoc commands",
	"tags": [],
	"description": "",
	"content": "For our first exercise, we are going to run some ad hoc commands to help you get a feel for how Ansible works. Ansible ad hoc commands enable you to perform tasks on remote nodes without having to write a playbook. They are very useful when you simply need to do one or two things quickly and often, to many remote nodes.\nWork with your Inventory To use the ansible command for host management, you need to provide an inventory file which defines a list of hosts to be managed from the control node. In this lab the inventory is provided by your instructor. The inventory is an ini formatted file listing your hosts, sorted in groups, additionally providing some variables. Have a look for yourself, in your code-server terminal run:\n[student@ansible-1 ~]$ cat lab_inventory/hosts [all:vars] ansible_user=student\u0026lt;N\u0026gt; ansible_ssh_pass=\u0026lt;password\u0026gt; ansible_port=22 [web] node1 ansible_host=\u0026lt;IP address\u0026gt; node2 ansible_host=\u0026lt;IP address\u0026gt; node3 ansible_host=\u0026lt;IP address\u0026gt; [control] ansible ansible_host=\u0026lt;IP address\u0026gt;  The environment for this lab uses SSH with password authentication to login to the managed nodes. For the sake of keeping things simple the password is put into the inventory file in clear text. In real world scenarios you would either use SSH key authentication or supply the password in a secure way, e.g. by using Ansible Vault.\n Note that each student has an individual lab environment so we left out the actual IPs and other data. As with the other cases, replace \u0026lt;N\u0026gt; with your actual student number.\n Ansible is already configured to use the inventory specific to your environment, you\u0026rsquo;ll learn how in a minute. For now let\u0026rsquo;s execute some simple commands to work with the inventory.\nTo reference inventory hosts, you supply a host pattern to the ansible command. Ansible has a --list-hosts option which can be useful for clarifying which managed hosts are referenced by the host pattern in an ansible command.\nThe most basic host pattern is the name for a single managed host listed in the inventory file. This specifies that the host will be the only one in the inventory file that will be acted upon by the ansible command. Run:\n[student@ansible-1 ~]$ ansible node1 --list-hosts hosts (1): node1 An inventory file can contain a lot more information, it can organize your hosts in groups or define variables. In our example, the current inventory has the groups web and control. Run Ansible with these host patterns and observe the output:\n[student@ansible-1 ~]$ ansible web --list-hosts [student@ansible-1 ~]$ ansible web,ansible --list-hosts [student@ansible-1 ~]$ ansible \u0026#39;node*\u0026#39; --list-hosts [student@ansible-1 ~]$ ansible all --list-hosts As you see it is OK to put systems in more than one group. For instance, a server could be both a web server and a database server. Note that in Ansible the groups are not necessarily hierarchical.\nThe inventory can contain more data. E.g. if you have hosts that run on non-standard SSH ports you can put the port number after the hostname with a colon. Or you could define names specific to Ansible and have them point to the \u0026ldquo;real\u0026rdquo; IP or hostname.\n The Ansible Configuration Files The behavior of Ansible can be customized by modifying settings in Ansible’s ini-style configuration file. Ansible will select its configuration file from one of several possible locations on the control node, please refer to the documentation.\nThe recommended practice is to create an ansible.cfg file in the directory from which you run Ansible commands. This directory would also contain any files used by your Ansible project, such as the inventory and playbooks. Another recommended practice is to create a file .ansible.cfg in your home directory.\n In the lab environment provided to you an .ansible.cfg file has already been created and filled with the necessary details in the home directory of your student\u0026lt;N\u0026gt; user on the control node:\n[student@ansible-1 ~]$ ls -la .ansible.cfg -rw-r--r--. 1 student\u0026lt;N\u0026gt; student\u0026lt;N\u0026gt; 231 14. Mai 17:17 .ansible.cfg Review the content of the file:\n[student@ansible-1 ~]$ cat .ansible.cfg [defaults] stdout_callback = yaml connection = smart timeout = 60 deprecation_warnings = False host_key_checking = False retry_files_enabled = False inventory = /home/student{{student}}/lab_inventory/hosts There are multiple configuration flags provided. Most of them are not of interest here, but make sure to note the last line: there the location of the inventory is provided. That is the way Ansible knew in the previous commands what inventory to use to lookup the nodes.\nPing a host Let\u0026rsquo;s start with something really basic - pinging a host. To do that we use the Ansible ping module. Basically, the ping module connects to the managed host, executes a small script there and collects the results. This ensures that the managed host is reachable and that Ansible is able to execute commands properly on it.\nThink of a module as a tool which is designed to accomplish a specific task.\n Ansible needs to know that it should use the ping module: The -m option defines which Ansible module to use. Options can be passed to the specified module using the -a option. In addition to the module Ansible needs to know what hosts it should run the task on, here you supply the group web.\n[student@ansible-1 ~]$ ansible web -m ping node2 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } [...] As you see each node in the web group reports the successful execution and the actual result - here \u0026ldquo;pong\u0026rdquo;.\nListing Modules and Getting Help Ansible comes with a lot of modules by default. To list all modules run:\n[student@ansible-1 ~]$ ansible-doc -l  In ansible-doc leave by pressing the button q. Use the up/down arrows to scroll through the content.\n To find a module try e.g.:\n[student@ansible-1 ~]$ ansible-doc -l | grep -i user Get help for a specific module including usage examples:\n[student@ansible-1 ~]$ ansible-doc user  Mandatory options are marked by a \u0026ldquo;=\u0026rdquo; in ansible-doc, optional ones by a \u0026ldquo;-\u0026rdquo;.\n Use the command module Now let\u0026rsquo;s see how we can run a good ol' fashioned Linux command and format the output using the command module. It simply executes the specified command on a managed host (note this time not a group but a hostname is used as host pattern):\n[student@ansible-1 ~]$ ansible node1 -m command -a \u0026#34;id\u0026#34; node1 | CHANGED | rc=0 \u0026gt;\u0026gt; uid=1001(student\u0026lt;N\u0026gt;) gid=1001(student{{ student }) groups=1001(student\u0026lt;N\u0026gt;) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 In this case the module is called command and the option passed with -a is the actual command to run. Try to run this ad hoc command on all managed hosts using the all host pattern.\nAnother example: Have a quick look at the kernel versions your hosts are running:\n[student@ansible-1 ~]$ ansible all -m command -a \u0026#39;uname -r\u0026#39; Sometimes it’s desirable to have the output for a host on one line:\n[student@ansible-1 ~]$ ansible all -m command -a \u0026#39;uname -r\u0026#39; -o  Like many Linux commands, ansible allows long-form options as well as short-form. For example ansible web --module-name ping is the same as running ansible web -m ping. We are going to be using the short-form options throughout this workshop.\n The copy module and permissions Using the copy module, execute an ad hoc command on node1 to change the contents of the /etc/motd file. The content is handed to the module through an option in this case.\nRun the following, but expect an error:\n[student@ansible-1 ~]$ ansible node1 -m copy -a \u0026#39;content=\u0026#34;Managed by Ansible\\n\u0026#34; dest=/etc/motd\u0026#39; As mentioned this produces an error:\nnode1 | FAILED! =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;checksum\u0026#34;: \u0026#34;a314620457effe3a1db7e02eacd2b3fe8a8badca\u0026#34;, \u0026#34;failed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;Destination /etc not writable\u0026#34; } The output of the ad hoc command is screaming FAILED in red at you. Why? Because user student\u0026lt;N\u0026gt; is not allowed to write the motd file.\nNow this is a case for privilege escalation and the reason sudo has to be setup properly. We need to instruct Ansible to use sudo to run the command as root by using the parameter -b (think \u0026ldquo;become\u0026rdquo;).\nAnsible will connect to the machines using your current user name (student\u0026lt;N\u0026gt; in this case), just like SSH would. To override the remote user name, you could use the -u parameter.\n For us it’s okay to connect as student\u0026lt;N\u0026gt; because sudo is set up. Change the command to use the -b parameter and run again:\n[student@ansible-1 ~]$ ansible node1 -m copy -a \u0026#39;content=\u0026#34;Managed by Ansible\\n\u0026#34; dest=/etc/motd\u0026#39; -b This time the command is a success:\nnode1 | CHANGED =\u0026gt; { \u0026#34;changed\u0026#34;: true, \u0026#34;checksum\u0026#34;: \u0026#34;4458b979ede3c332f8f2128385df4ba305e58c27\u0026#34;, \u0026#34;dest\u0026#34;: \u0026#34;/etc/motd\u0026#34;, \u0026#34;gid\u0026#34;: 0, \u0026#34;group\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;md5sum\u0026#34;: \u0026#34;65a4290ee5559756ad04e558b0e0c4e3\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;0644\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;secontext\u0026#34;: \u0026#34;system_u:object_r:etc_t:s0\u0026#34;, \u0026#34;size\u0026#34;: 19, \u0026#34;src\u0026#34;: \u0026#34;/home/student\u0026lt;N\u0026gt;/.ansible/tmp/ansible-tmp-1557857641.21-120920996103312/source\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;file\u0026#34;, \u0026#34;uid\u0026#34;: 0 Use Ansible with the generic command module to check the content of the motd file:\n[student@ansible-1 ~]$ ansible node1 -m command -a \u0026#39;cat /etc/motd\u0026#39; node1 | CHANGED | rc=0 \u0026gt;\u0026gt; Managed by Ansible Run the ansible node1 -m copy …​ command from above again. Note:\n  The different output color (proper terminal config provided).\n  The change from \u0026quot;changed\u0026quot;: true, to \u0026quot;changed\u0026quot;: false,.\n  The first line says SUCCESS instead of CHANGED.\n  This makes it a lot easier to spot changes and what Ansible actually did.\n Challenge Lab: Modules   Using ansible-doc\n  Find a module that uses yum to manage software packages.\n  Look up the help examples for the module to learn how to install a package in the latest version.\n    Run an Ansible ad hoc command to install the package \u0026ldquo;vim\u0026rdquo; in the latest version on all available nodes.\n  Use the copy ad hoc command from above as a template and change the module and options.\n Click here for Solution   [student@ansible-1 ~]$ ansible-doc -l | grep -i yum [student@ansible-1 ~]$ ansible-doc yum [student@ansible-1 ~]$ ansible all -m yum -a \u0026#39;name=vim state=latest\u0026#39; -b \n  "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/",
	"title": "Ansible Tower Advanced",
	"tags": [],
	"description": "",
	"content": "Ansible Tower Advanced   Exercise 1 - Ansible Tower Advanced\n  Exercise 2 - Introduction to Ansible Tower Clustering\n  Exercise 3 - There is more to Tower than the Web UI\n  Exercise 4 - Creating Tower Objects Using awx\n  Exercise 5 - Run a Job in a Cluster\n  Exercise 6 - Tower Instance Groups\n  Exercise 7 - Start Parallel Jobs across Instances\n  Exercise 8 - Isolated Nodes\n  Exercise 9 - Advanced Inventories\n  Exercise 10 - OPTIONAL: Well Structured Content Repositories\n  Exercise 11 - OPTIONAL: Discovering the Tower API\n  "
},
{
	"uri": "https://lj020326.github.io/ansible-collections/3-using-collections-from-roles/",
	"title": "Collections from Roles",
	"tags": [],
	"description": "",
	"content": "In this exercise you will learn how collections are used from within Ansible roles. As promised we\u0026rsquo;ll explain the collection name resolution logic in more depth first. Then you\u0026rsquo;ll see how to call a collection from an Ansible role using collection fully qualified collection name (FQCN).\nRunning collections from an Ansible role First and to keep you home directory tidy, create an exercise folder:\n[student@ansible-1 ~]$ mkdir exercise-03 [student@ansible-1 ~]$ cd exercise-03 For this lab, we will use the ansible.posix collection again, which contains a series of POSIX oriented modules and plugins for systems management. You should have installed the collection in the first exercise, if not, just do it now:\n[student@ansible-1 ~]$ ansible-galaxy collection install ansible.posix Process install dependency map Starting collection install process Skipping \u0026#39;ansible.posix\u0026#39; as it is already installed  See how the command didn\u0026rsquo;t fail or complain if the collection was installed already but just let\u0026rsquo;s you know it was already there.\n Approach 1: Collections loaded as metadata There are two approaches to use Ansible Collections in your role. The first approach is to specify the collection you want to use in your roles metadata.\nFirst we\u0026rsquo;ll create a simple role. Start with creating a new role scaffold using the ansible-galaxy init command (make sure you changed into your exercise folder):\n[student@ansible-1 exercise-03]$ ansible-galaxy init --init-path roles selinux_manage_meta - Role selinux_manage_meta was created successfully Now you have to edit a couple of files. First edit the role metadata in roles/selinux_manage_meta/meta/main.yml and append the following lines at the end of the file, don\u0026rsquo;t change anything else:\n# Collections list collections: - ansible.posix A role without some tasks is not too interesting, go and edit the roles/selinux_manage_meta/tasks/main.yml file and add the following tasks (make sure to keep the YAML start --- in place):\n--- # tasks file for selinux_manage_meta - name: Enable SELinux enforcing mode selinux: policy: targeted state: \u0026quot;{{ selinux_mode }}\u0026quot; - name: Enable booleans seboolean: name: \u0026quot;{{ item }}\u0026quot; state: true persistent: true loop: \u0026quot;{{ sebooleans_enable }}\u0026quot; - name: Disable booleans seboolean: name: \u0026quot;{{ item }}\u0026quot; state: false persistent: true loop: \u0026quot;{{ sebooleans_disable }}\u0026quot;  We\u0026rsquo;re using the simple module name. Ansible uses the information from the collections list in the metadata file to locate the collection(s) used.\n Every well-written role should come with sensible defaults, edit the roles/selinux_manage_meta/defaults/main.yml to define default values for role variables:\n--- # defaults file for selinux_manage_meta selinux_mode: enforcing sebooleans_enable: [] sebooleans_disable: [] As a last step clean up the unused folders of the role:\n[student@ansible-1 exercise-03]$ rm -rf roles/selinux_manage_meta/{tests,vars,handlers,files,templates} And you are done with the role! Run tree to check everything looks good:\n[student@ansible-1 exercise-03]$ tree . └── roles └── selinux_manage_meta ├── defaults │ └── main.yml ├── meta │ └── main.yml ├── README.md └── tasks └── main.yml We can now test the new role with a basic playbook. Create the playbook.yml file in the exercise folder with the following content:\n--- - hosts: localhost become: true vars: sebooleans_enable: - httpd_can_network_connect - httpd_mod_auth_pam sebooleans_disable: - httpd_enable_cgi roles: - selinux_manage_meta Run the playbook and check the results:\n[student@ansible-1 exercise-03]$ ansible-playbook playbook.yml [WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match \u0026#39;all\u0026#39; PLAY [localhost] ****************************************************************************************************** TASK [Gathering Facts] ************************************************************************************************ ok: [localhost] TASK [selinux_manage_meta : Enable SELinux enforcing mode] ************************************************************ ok: [localhost] TASK [selinux_manage_meta : Enable booleans] ************************************************************************** changed: [localhost] =\u0026gt; (item=httpd_can_network_connect) changed: [localhost] =\u0026gt; (item=httpd_mod_auth_pam) TASK [selinux_manage_meta : Disable booleans] ************************************************************************* changed: [localhost] =\u0026gt; (item=httpd_can_network_connect) PLAY RECAP ************************************************************************************************************ localhost : ok=4 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Approach 2: Collections loaded with FQCN The second approach to use collections in roles uses the collection FQCN to call the related modules and plugins. To better demonstrate the differences, we will implement a new version of the previous role with the FQCN approach without changing the inner logic.\nTo make this easy we\u0026rsquo;ll just copy and edit the role we created above:\n[student@ansible-1 exercise-03]$ cp -r roles/selinux_manage_meta/ roles/selinux_manage_fqcn Now change the file roles/selinux_manage_fqcn/tasks/main.yml so it uses the FQCN for the modules. It should look like this:\n--- # tasks file for selinux_manage_fqcn - name: Enable SELinux enforcing mode ansible.posix.selinux: policy: targeted state: \u0026quot;{{ selinux_mode }}\u0026quot; - name: Enable booleans ansible.posix.seboolean: name: \u0026quot;{{ item }}\u0026quot; state: true persistent: true loop: \u0026quot;{{ sebooleans_enable }}\u0026quot; - name: Disable booleans ansible.posix.seboolean: name: \u0026quot;{{ item }}\u0026quot; state: false persistent: true loop: \u0026quot;{{ sebooleans_disable }}\u0026quot;  Notice the usage of the modules FQCN in the role tasks. Ansible will directly look for the installed collection from within the role task, no matter if the collections keyword is defined at playbook level.\n The remaining files can stay unchanged. To test the FQCN role modify the previously created playbook.yml file to use the new role:\n--- - hosts: localhost become: true vars: sebooleans_enable: - httpd_can_network_connect - httpd_mod_auth_pam sebooleans_disable: - httpd_enable_cgi roles: - selinux_manage_fqcn Run the playbook again and check the results:\n[student@ansible-1 exercise-03]$ ansible-playbook playbook.yml [WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match \u0026#39;all\u0026#39; PLAY [localhost] ****************************************************************************************************** TASK [Gathering Facts] ************************************************************************************************ ok: [localhost] TASK [selinux_manage_meta : Enable SELinux enforcing mode] ************************************************************ ok: [localhost] TASK [selinux_manage_meta : Enable booleans] ************************************************************************** changed: [localhost] =\u0026gt; (item=httpd_can_network_connect) ok: [localhost] =\u0026gt; (item=httpd_mod_auth_pam) TASK [selinux_manage_meta : Disable booleans] ************************************************************************* changed: [localhost] =\u0026gt; (item=httpd_can_network_connect) PLAY RECAP ************************************************************************************************************ localhost : ok=4 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 The Playbook should run in the same way with the same output like above, where you loaded the collection using the role metadata.\nTakeaways   Collections can be called from roles using the collections list defined in meta/main.yml.\n  Collections can be called from roles using their FQCN directly from the role tasks.\n  "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-getting-started/3-projects/",
	"title": "Projects &amp; job templates",
	"tags": [],
	"description": "",
	"content": "A Tower Project is a logical collection of Ansible Playbooks. You can manage your playbooks by placing them into a source code management (SCM) system supported by Tower, including Git, Subversion, and Mercurial.\nYou should definitely keep your Playbooks under version control. In this lab we’ll use Playbooks that are provided in a Github repository.\nSetup Git Repository For this lab we will use playbooks stored in this Git repository, using the summit_2020 tag:\nhttps://github.com/ansible/workshop-examples\nA Playbook to install the Apache webserver has already been committed to the directory rhel/apache, apache_install.yml, here for reference:\n--- - name: Apache server installed hosts: all tasks: - name: latest Apache version installed yum: name: httpd state: latest - name: latest firewalld version installed yum: name: firewalld state: latest - name: firewalld enabled and running service: name: firewalld enabled: true state: started - name: firewalld permits http service firewalld: service: http permanent: true state: enabled immediate: yes - name: Apache enabled and running service: name: httpd enabled: true state: started  Note the difference to other Playbooks you might have written! Most importantly there is no become and hosts is set to all.\n To configure and use this repository as a Source Control Management (SCM) system in Tower you have to create a Project that uses the repository\nCreate the Project   Go to RESOURCES → Projects in the side menu view click the button. Fill in the form:\n  NAME: Ansible Workshop Examples\n  ORGANIZATION: Default\n  SCM TYPE: Git\n  Now you need the URL to access the repo. You could get the URL in Github as Clone URL. Enter the URL into the Project configuration:\n  SCM URL: https://github.com/ansible/workshop-examples.git\n  SCM BRANCH/TAG/COMMIT: summit_2020\n  SCM UPDATE OPTIONS: Tick all four boxes to always get a fresh copy of the repository and to update the repository when launching a job.\n  Click SAVE\n  The new Project will be synced automatically after creation. But you can also do this manually: Sync the Project again with the Git repository by going to the Projects view and clicking the circular arrow Get latest SCM revision icon to the right of the Project.\nAfter starting the sync job, go to the Jobs view: there is a new job for the update of the Git repository.\nCreate a Job Template and Run a Job A job template is a definition and set of parameters for running an Ansible job. Job templates are useful to execute the same job many times. So before running an Ansible Job from Tower you must create a Job Template that pulls together:\n  Inventory: On what hosts should the job run?\n  Credentials What credentials are needed to log into the hosts?\n  Project: Where is the Playbook?\n  What Playbook to use?\n  Okay, let’s just do that: Go to the Templates view, click the button and choose Job Template.\nRemember that you can often click on magnifying glasses to get an overview of options to pick to fill in fields.\n   NAME: Install Apache\n  JOB TYPE: Run\n  INVENTORY: Workshop Inventory\n  PROJECT: Ansible Workshop Examples\n  PLAYBOOK: rhel/apache/apache_install.yml\n  CREDENTIAL: Workshop Credentials\n  We need to run the tasks as root so check Enable privilege escalation\n  Click SAVE\n  You can start the job by directly clicking the blue LAUNCH button, or by clicking on the rocket in the Job Templates overview. After launching the Job Template, you are automatically brought to the job overview where you can follow the playbook execution in real time:\nSince this might take some time, have a closer look at all the details provided:\n  All details of the job template like inventory, project, credentials and playbook are shown.\n  Additionally, the actual revision of the playbook is recorded here - this makes it easier to analyse job runs later on.\n  Also the time of execution with start and end time is recorded, giving you an idea of how long a job execution actually was.\n  On the right side, the output of the playbook run is shown. Click on a node underneath a task to get detailed information for the task.\n  After the Job has finished go to the main Jobs view: All jobs are listed here, you should see directly before the Playbook run an SCM update was started. This is the Git update we configured for the Project on Job Template launch!\nChallenge Lab: Check the Result Time for a little challenge:\n Use an ad hoc command on all hosts to make sure Apache has been installed and is running.  You have already been through all the steps needed, so try this for yourself.\nWhat about systemctl status httpd?\n Click here for Solution     Go to Inventories → Workshop Inventory\n  In the HOSTS view select all hosts and click RUN COMMANDS\n  MODULE: command\n  ARGUMENTS: systemctl status httpd\n  MACHINE CREDENTIALS: Workshop Credentials\n  Click LAUNCH\n    It should all look good!\nWhat About Some Practice? Here is a list of tasks:\nPlease make sure to finish these steps as the next chapter depends on it!\n   Create a new inventory called Webserver and make only node1 member of it.\n  Copy the Install Apache template using the copy icon in the Templates view\n  Change the name to Install Apache Ask\n  Change the INVENTORY setting of the Project so it will prompt for the inventory on launch (tick the appropriate box).\n  SAVE\n  Launch the Install Apache Ask template.\n  It will now ask for the inventory to use, choose the Webserver inventory and click NEXT and LAUNCH\n  Wait until the Job has finished and make sure it ran only on node1\n  The Job didn’t change anything because Apache was already installed in the latest version.\n "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/3-awx-cli-intro/",
	"title": "There is more to Tower than the Web UI",
	"tags": [],
	"description": "",
	"content": "This is an advanced Tower lab so we don’t really want you to use the web UI for everything. Tower’s web UI is well done and helps with a lot of tasks, but same as in system administration it’s often handy to be able to use the command line or scripts for certain tasks.\nWe’ve incorporated different ways to work with Tower in this lab guide and hope you’ll find it helpful. The first step we do is install the AWX CLI utility.\nAWX CLI is the official command-line client for AWX and Red Hat Ansible Tower. It uses naming and structure consistent with the AWX HTTP API, provides consistent output formats with optional machine-parsable formats.\n We’ll install it on your Tower node1 using the official repository RPM packages. Use the VSCode terminal window you opened before to install AWX CLI as root:\n[student@ansible-1 ~]$ sudo -i [ansible-1 ~]# yum-config-manager --add-repo https://releases.ansible.com/ansible-tower/cli/ansible-tower-cli-el8.repo [ansible-1 ~]# yum install ansible-tower-cli -y [ansible-1 ~]# exit  Please make sure to leave the root shell after installation of the package!\n After installing the tool, you have to configure authentication. The preferred way is to create a token and export it into an environment variable. After this you can seamlessly use awx commands in this shell. First set a number of environment variables to define your connection:\nReplace student number and LABID!\n [student@ansible-1 ~]$ export TOWER_HOST=https://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com [student@ansible-1 ~]$ export TOWER_USERNAME=admin [student@ansible-1 ~]$ export TOWER_PASSWORD=\u0026#39;VERY_SECRET_PASSWORD\u0026#39; [student@ansible-1 ~]$ export TOWER_VERIFY_SSL=false  Feel free to write this into a new file using the code-server editor and then to use source \u0026lt;filename\u0026gt; to set the environment variables. This way if you loose connection to code-server you can easily re-set the vars.\n Then use awx to login and print out the access token and to save it to a file at the same time:\n[student@ansible-1 ~]$ awx login -f human | tee token  We are saving the export TOWER_OAUTH_TOKEN=\u0026lt;YOUR_TOKEN\u0026gt; command line output to the file token using tee here to be able to set the environment variable more easily.\n Finally set the environment variable with the token using the line the command printed out:\n[student@ansible-1 ~]$ source token Now that the access token is available in your shell, test awx is working. First run it without arguments to get a list of resources you can manage with it:\n[student@ansible-1 ~]$ awx --help  And then test something, e.g. (leave out -f human if you\u0026rsquo;re a JSON fan\u0026hellip;) ;)\n[student@ansible-1 ~]$ awx -f human user list  When trying to find a awx command line for something you want to do, just move one by one.\n Example: Need to create an inventory\u0026hellip;\n[student@ansible-1 ~]$ awx --help  Okay, there is an inventory resource. Let’s see…\n[student@ansible-1 ~]$ awx inventory  Well, the create action sounds like what I had in mind. But what arguments do I need? Just run:\n[student@ansible-1 ~]$ awx inventory create  And you\u0026rsquo;ll get the required and optional arguments for the create action!\nChallenge Lab: awx To practice your awx skills, here is a challenge:\n  Try to change the idle time out of the Tower web UI, it’s 1800 seconds by default. Set it to, say, 7200. Using awx, of course.\n  Start by looking for a resource type awx provides using \u0026ndash;help that sounds like it has something to do with changing settings.\n  Look at the available awx commands for this resource type.\n  Use the commands to have a look at the parameters settings and change it.\n  The configuration parameter is called SESSION_COOKIE_AGE\n Click here for Solution   [student@ansible-1 ~]$ awx setting list | grep SESSION [student@ansible-1 ~]$ awx setting modify SESSION_COOKIE_AGE 7200 [student@ansible-1 ~]$ awx setting list | grep SESSION \n  If you want to, go to the web UI of any node (not just the one you connected awx to) and check the setting under ADMINISTRATION→Settings→System.\n"
},
{
	"uri": "https://lj020326.github.io/ansible-getting-started/3-playbook/",
	"title": "Writing Your First Playbook",
	"tags": [],
	"description": "",
	"content": "While Ansible ad hoc commands are useful for simple operations, they are not suited for complex configuration management or orchestration scenarios. For such use cases Playbooks are the way to go.\nPlaybooks are files which describe the desired configurations or steps to implement on managed hosts. Playbooks can change lengthy, complex administrative tasks into easily repeatable routines with predictable and successful outcomes.\nA Playbook is where you can take some of those ad hoc commands you just ran and put them into a repeatable set of Plays and Tasks.\nA Playbook can have multiple Plays and a Play can have one or multiple Tasks. In a Task a Module is called, like the Modules in the previous chapter.\n The goal of a Play is to map a group of hosts to a list of Tasks. The goal of a Task is to implement Modules against those hosts.  Here is a nice analogy: When Ansible Modules are the tools in your workshop, the Inventory is the list of materials and the Playbooks are the instructions.\n Playbook Basics Playbooks are text files written in YAML format and therefore need:\n  to start with three dashes (---)\n  proper indentation using spaces and not tabs!\n  There are some important concepts:\n  hosts: the managed hosts to perform the tasks on\n  tasks: the operations to be performed by invoking Ansible modules and passing them the necessary options.\n  become: privilege escalation in Playbooks, same as using -b in the ad hoc command.\n  The ordering of the contents within a Playbook is important, because Ansible executes plays and tasks in the order they are presented.\n A Playbook should be idempotent, so if a Playbook is run once to put the hosts in the correct state, it should be safe to run it a second time and it should make no further changes to the hosts.\nMost Ansible modules are idempotent, so it is relatively easy to ensure this is true.\n Creating a Directory Structure and File for your Playbook Enough theory, it’s time to create your first Playbook. In this lab you create a Playbook to set up an Apache webserver in three steps:\n  First step: Install httpd package\n  Second step: Enable/start httpd service\n  Third step: Create an index.html file\n  This Playbook makes sure the package containing the Apache webserver is installed on node1.\nThere is a best practice on the preferred directory structures for playbooks. We strongly encourage you to read and understand these practices as you develop your Ansible ninja skills. That said, our playbook today is very basic and creating a complex structure will just confuse things.\nInstead, we are going to create a very simple directory structure for our playbook, and add just a couple of files to it.\nIn your browser, bring up your code-server terminal (you opened one in the first section) and create a directory called ansible-files in your home directory and change into it:\n[student@ansible-1 ~]$ mkdir ansible-files [student@ansible-1 ~]$ cd ansible-files/ Now use code-server to add a file called apache.yml with the following content.\nIf you are unsure how to use code-server (basically like VSCode), have a quick look at the Visual Studio Code Server introduction\n --- - name: Apache server installed hosts: node1 become: yes This shows one of Ansible’s strengths: The Playbook syntax is easy to read and understand. In this Playbook:\n  A name is given for the play via name:.\n  The host to run the playbook against is defined via hosts:.\n  We enable user privilege escalation with become:.\n  You obviously need to use privilege escalation to install a package or run any other task that requires root permissions. This is done in the Playbook by become: yes.\n Now that we\u0026rsquo;ve defined the play, let\u0026rsquo;s add a task to get something done. We will add a task in which yum will ensure that the Apache package is installed in the latest version. Modify the file so that it looks like the following listing using the code-server editor:\n--- - name: Apache server installed hosts: node1 become: yes tasks: - name: latest Apache version installed yum: name: httpd state: latest  Since playbooks are written in YAML, alignment of the lines and keywords is crucial. Make sure to vertically align the t in task with the b in become. Once you are more familiar with Ansible, make sure to take some time and study a bit the YAML Syntax.\n In the added lines:\n  We started the tasks part with the keyword tasks:.\n  A task is named and the module for the task is referenced. Here it uses the yum module.\n  Parameters for the module are added:\n  name: to identify the package name\n  state: to define the wanted state of the package\n    The module parameters are individual to each module. If in doubt, look them up again with ansible-doc.\n Save your playbook.\nRunning the Playbook Playbooks are executed using the ansible-playbook command on the control node. Before you run a new Playbook it’s a good idea to check for syntax errors. Head over to the code-server terminal and run:\n[student@ansible-1 ansible-files]$ ansible-playbook --syntax-check apache.yml Now you should be ready to run your Playbook:\n[student@ansible-1 ansible-files]$ ansible-playbook apache.yml The output should not report any errors but provide an overview of the tasks executed and a Play Recap summarizing what has been done. There is also a task called Gathering Facts listed: this is a built-in task that runs automatically at the beginning of each Play. It collects information about the managed nodes. Exercises later on will cover this in more detail.\nUse SSH to make sure Apache has been installed on node1. The necessary IP address is provided in the inventory. Grep for the IP address there and use it to SSH to the node.\n[student@ansible-1 ansible-files]$ grep node1 ~/lab_inventory/hosts node1 ansible_host=11.22.33.44 [student@ansible-1 ansible-files]$ ssh 11.22.33.44 Last login: Wed May 15 14:03:45 2019 from 44.55.66.77 Managed by Ansible [...] [ec2-user@node1 ~]$ rpm -qi httpd Name : httpd Version : 2.4.6 [...] Log out of node1 with the command exit so that you are back on the control host, and verify the installed package with an Ansible ad hoc command!\n[student@ansible-1 ansible-files]$ ansible node1 -m command -a \u0026#39;rpm -qi httpd\u0026#39; Run the Playbook a second time, and compare the output: The output changed from changed to ok, and the color changed from yellow to green. Also the PLAY RECAP output is different now. This make it easy to spot what Ansible actually did.\nExtend your Playbook: Start \u0026amp; Enable Apache The next part of the Playbook makes sure the Apache webserver is enabled and started on node1.\nOn the control host, as your student user, edit the file ~/ansible-files/apache.yml again to add a second task using the service module. The Playbook should now look like this:\n--- - name: Apache server installed hosts: node1 become: yes tasks: - name: latest Apache version installed yum: name: httpd state: latest - name: Apache enabled and running service: name: httpd enabled: true state: started Again: what these lines do is easy to understand:\n  a second task is created and named\n  a module is specified (service)\n  parameters for the module are supplied\n  With the second task we make sure the Apache server is indeed running on the target machine. Run your extended Playbook:\n[student@ansible-1 ansible-files]$ ansible-playbook apache.yml Note the output now: Some tasks are shown as ok in green and one is shown as changed in yellow.\n  Use an Ansible ad hoc command again to make sure Apache has been enabled and started, e.g. with: systemctl status httpd.\n  Run the Playbook a second time to get used to the change in the output.\n  Extend your Playbook: Create an index.html Check that the tasks were executed correctly and Apache is accepting connections: Make an HTTP request using Ansible’s uri module in an ad hoc command from the control node. Make sure to replace the IP with the IP for the node from the inventory.\nExpect a lot of red lines and a 403 status\n [student@ansible-1 ansible-files]$ ansible localhost -m uri -a \u0026#34;url=http://\u0026lt;IP\u0026gt;\u0026#34; There are a lot of red lines and an error: As long as there is not at least an index.html file to be served by Apache, it will throw an ugly HTTP Error 403: Forbidden status and Ansible will report an error.\nSo why not use Ansible to deploy a simple index.html file? Create the file ~/ansible-files/index.html on the control node:\n\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Apache is running fine\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; You already used Ansible’s copy module to write text supplied on the command line into a file. Now you’ll use the module in your Playbook to actually copy a file:\nOn the control node as your student user edit the file ~/ansible-files/apache.yml and add a new task utilizing the copy module. It should now look like this:\n--- - name: Apache server installed hosts: node1 become: yes tasks: - name: latest Apache version installed yum: name: httpd state: latest - name: Apache enabled and running service: name: httpd enabled: true state: started - name: copy index.html copy: src: ~/ansible-files/index.html dest: /var/www/html/ You are getting used to the Playbook syntax, so what happens? The new task uses the copy module and defines the source and destination options for the copy operation as parameters.\nRun your extended Playbook:\n[student@ansible-1 ansible-files]$ ansible-playbook apache.yml   Have a good look at the output\n  Run the ad hoc command using the \u0026ldquo;uri\u0026rdquo; module from further above again to test Apache: The command should now return a friendly green \u0026ldquo;status: 200\u0026rdquo; line, amongst other information.\n  Practice: Apply to Multiple Host This was nice but the real power of Ansible is to apply the same set of tasks reliably to many hosts.\n So what about changing the apache.yml Playbook to run on node1 and node2 and node3?  As you might remember, the inventory lists all nodes as members of the group web:\n[web] node1 ansible_host=11.22.33.44 node2 ansible_host=22.33.44.55 node3 ansible_host=33.44.55.66  The IP addresses shown here are just examples, your nodes will have different IP addresses.\n Change the Playbook to point to the group web:\n--- - name: Apache server installed hosts: web become: yes tasks: - name: latest Apache version installed yum: name: httpd state: latest - name: Apache enabled and running service: name: httpd enabled: true state: started - name: copy index.html copy: src: ~/ansible-files/index.html dest: /var/www/html/ Now run the Playbook:\n[student@ansible-1 ansible-files]$ ansible-playbook apache.yml Finally check if Apache is now running on all servers. Identify the IP addresses of the nodes in your inventory first, and afterwards use them each in the ad hoc command with the uri module as we already did with the node1 above. All output should be green.\n"
},
{
	"uri": "https://lj020326.github.io/ansible-collections/",
	"title": "Ansible Collections",
	"tags": [],
	"description": "",
	"content": "Ansible Collections Workshop  Exercise 1 - Introduction Exercise 2 - Collections from playbook Exercise 3 - Collections from roles Exercise 4 - Collections from tower Exercise 5 - Creating Collections Exercise 6 - Use Automation Hub  Additional Resources  Ansible Docs: Using Collections Ansible Collections Overview Ansible Docs: Developing Collections Blog Post: Introducing: The AWX and Ansible Tower Collections  "
},
{
	"uri": "https://lj020326.github.io/ansible-collections/4-using-collections-from-tower/",
	"title": "Collections in Tower",
	"tags": [],
	"description": "",
	"content": "Red Hat Ansible Tower supports Ansible Collections starting with version 3.5 - earlier version will not automatically install and configure them for you. To make sure Ansible Collections are recognized by Red Hat Ansible Tower a requirements file is needed and has to be stored in the proper directory.\nAnsible Galaxy is already configured by default, however if you want your Red Hat Ansible Tower to prefer and fetch content from the Red Hat Automation Hub, additional configuration changes are required. They are addressed in a the chapter Use Automation Hub in this lab.\nIn this exercise you will learn how to define an Ansible Collection as a requirement in a format recognized by Red Hat Ansible Tower. We\u0026rsquo;ll be using the ansible.posix collection again from Ansible Galaxy. As you probably know for Ansible Tower to access the needed bits and pieces a version control system is needed. For the sake of keeping this lab setup easy, we\u0026rsquo;ll set up a local Git server for this.\nSet up a Local Git Server So, let’s get started. We have to create a simplistic Git server on our control host. Typically you would work with GitHub, GitLab, Gitea, or any other Git server.\nMake sure to run these steps from your users home directory!\n [student@ansible-1 ~]$ wget https://raw.githubusercontent.com/lj020326/ansible-labs/master/content/ansible-collections/4-using-collections-from-tower/simple_git.yml [student@ansible-1 ~]$ ansible-playbook simple_git.yml -e \u0026quot;git_project=tower_collections\u0026quot; Next we will clone the repository on the control host. To enable you to work with git on the command line the SSH key for user ec2-user was already added to the Git user git. Next, clone the repository on the control machine:\n[student@ansible-1 ~]$ git clone git@ansible-1:projects/tower_collections # Message \u0026#34;warning: You appear to have cloned an empty repository.\u0026#34; is OK and can be ignored [student@ansible-1 ~]$ git config --global push.default simple [student@ansible-1 ~]$ git config --global user.name \u0026#34;Your Name\u0026#34; [student@ansible-1 ~]$ git config --global user.email you@example.com [student@ansible-1 ~]$ cd tower_collections/  The repository is currently empty. The three config commands are just there to avoid warnings from Git.\n You now have a local Git server that can be accessed via SSH from Tower.\nCreate Content for the Ansible Tower Project Red Hat Ansible Tower can download and install Ansible Collections automatically before executing a Job Template. If a collections/requirements.yml exists in your project, it will be parsed and the Ansible Collections specified in this file will be automatically installed.\nStarting with Red Hat Ansible Tower 3.6 the working directory for the Job Template is in /tmp. Since the Ansible Collection is downloaded into this directory before the Job Template is executed, you will not find temporary files of your Ansible Collection in /var/lib/awx/projects/.\n The format of the requirements.yml for Ansible Collections is very similar to the one for roles, however it is very important to store in the folder collections.\nLet\u0026rsquo;s create the files needed to see how you can use collections in Ansible Tower. This is of course just a simple example. First create the collections directory in your Git repo (you should have changed into tower_collections already above):\n[student@ansible-1 tower_collections]$ mkdir collections [student@ansible-1 tower_collections]$ cd collections Then create the requirements.yml file listing the collection(s) you need:\n--- collections: - ansible.posix As this is a simple example we\u0026rsquo;ll just add a Playbook to the Git repo now. Normally you would have a lot more content in your project repository. So what could we do as an example instead of using the ansible.posix collection again? Let\u0026rsquo;s create a Playbook to configure an at job:\n--- - name: Install AT Job hosts: all tasks: - name: at command needs to be installed yum: name: at state: present - name: Schedule a command to execute in 20 minutes as root ansible.posix.at: command: ls -d / \u0026gt;/dev/null count: 20 units: minutes Save the file as configure_at_job.yml.\nNote the usage of the Fully Qualified Collection Name in the Playbook\n Make sure everything looks fine:\n[student@ansible-1 tower_collections]$ tree . ├── collections │ └── requirements.yml └── configure_at_job.yml So far you created the code only locally on the control host, now you are ready to add it to the repository and push it:\n[student@ansible-1 tower_collections]$ git add collections configure_at_job.yml [student@ansible-1 tower_collections]$ git commit -m \u0026#34;Adding requirements.yml and playbook\u0026#34; [student@ansible-1 tower_collections]$ git push Create the Project and Job Template Now it\u0026rsquo;s time to access your Ansible Tower web UI if you haven\u0026rsquo;t done so out of curiosity already. Point your browser to the URL you were given on the lab landing page, similar to https://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com (replace \u0026lt;N\u0026gt; with your student number and \u0026lt;LABID\u0026gt; with the ID of this lab) and log in as admin. You can find the password again on the lab landing page.\nTo run your new Playbook in Ansible Tower you have to configure a number of objects:\n An Inventory with the managed hosts Machine Credentials to access the managed hosts Git Credentials to access your Git repository via SSH The Git repo as Project A Job Template to run the Playbook  We\u0026rsquo;ll be a bit verbose for students new to Ansible Tower. If you are an Ansible Tower old-hand, just skip through and finish the configuration steps shown.\nInventory and Machine Credentials The inventory Workshop Inventory and the machine credentials Workshop Credentials have already been created in your lab environment.\nConfigure SCM Credentials Now we will configure the credentials to access our the Git repo on your control host via SSH. In the RESOURCES menu choose Credentials. Now:\nClick the button to add new credentials\n NAME: Git Credentials ORGANIZATION: Click on the magnifying glass, pick Default and click SELECT CREDENTIAL TYPE: Click on the magnifying glass, pick Source Control as type and click SELECT (you will have to use the search or cycle through the types to find it). USERNAME: ec2-user  As we are using SSH key authentication, you have to provide an SSH private key that can be used to access the host with the Git repo as the user git.\nThe Playbook we used to configure Git added the SSH private key to the authorized_keys of user git\n Bring up your code-server terminal on Tower and use cat to get the SSH private key:\n[ansible-1 ~]$ cat ~/.ssh/aws-private.pem -----BEGIN RSA PRIVATE KEY----- MIIEpAIBAAKCAQEA2nnL3m5sKvoSy37OZ8DQCTjTIPVmCJt/M02KgDt53+baYAFu1TIkC3Yk+HK1 [...] -----END RSA PRIVATE KEY-----   Copy the complete private key (including \u0026ldquo;BEGIN\u0026rdquo; and \u0026ldquo;END\u0026rdquo; lines) from the output and paste it into the SSH PRIVATE KEY field in the web UI.\n  Click SAVE\n  You have now setup credentials to access the Git repo on your control host.\nSet up the Project It\u0026rsquo;s time to set up the Tower Project pointing to your Git repository holding your Playbook and collections requirements file.\n Go to RESOURCES → Projects in the side menu view click the button. Fill in the form: NAME: Collections Repo ORGANIZATION: Default SCM TYPE: Git  Now you need the URL to access the repo. You could get the URL in Github as Clone URL. Enter the URL into the Project configuration:\n SCM URL: git@ansible-1:projects/tower_collections SCM CREDENTIAL: Click the magnifying glass and choose Git Credentials, click SELECT SCM UPDATE OPTIONS: Tick the first three boxes to always get a fresh copy of the repository and to update the repository when launching a job. Click SAVE  The new Project will be synced automatically after creation. If everything went fine, you should see a green icon to the left of the new Project.\nCreate the Job Template and run it The last step is to create a Job Template to run the Playbook. Go to the Templates view, click the button and choose Job Template.\n  NAME: Install AT Job\n  JOB TYPE: Run\n  INVENTORY: Workshop Inventory\n  PROJECT: Collections Repo\n  PLAYBOOK: configure_at_job.yml\n  CREDENTIAL: Workshop Credentials\n  We need to run the tasks as root so check Enable privilege escalation\n  Click SAVE\n  You can start the job by directly clicking the blue LAUNCH button, or by clicking on the rocket in the Job Templates overview. After launching the Job Template, you are automatically brought to the job overview where you can follow the playbook execution in real time.\nAfter the Job has finished bring up your VSCode terminal, as the job was run on all three managed nodes and the control/ Ansible Tower node, you can simply check the result here. Run sudo at -l and you should see your job was scheduled successfully.\nTroubleshooting Since Red Hat Ansible Tower does only check for updates in the repository in which you stored your Playbook, it might not do a refresh if there was a change in the Ansible Collection used by your Playbook. This happens particularly if you also combine Roles and Collections.\nIn this case you should check the option Delete on Update which will delete the entire local directory during a refresh.\nIf there is a problem while parsing your requirements.yml it\u0026rsquo;s worth testing it with the ansible-galaxy command. As a reminder, Red Hat Ansible Tower basically also just runs the command for you with the appropriate parameters, so testing this works manually makes a lot of sense.\nansible-galaxy collection install -r collections/requirements.yml -f  The -f switch will forces a fresh installation of the specified Ansible Collections, otherwise ansible-galaxy will only install it, if it wasn\u0026rsquo;t already installed. You can also use the --force-with-deps switch to make sure Ansible Collections which have dependencies to others are refreshed as well.\n "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/4-awx-cli-exercises/",
	"title": "Creating Tower Objects Using `awx`",
	"tags": [],
	"description": "",
	"content": "Next we want to configure Tower so that we can run Ansible jobs. For this we need Inventories, Projects, Credentials and Job Templates. When you first start with Tower, this is usually done via web UI. But using Tower more often and especially when you want to boot-strap a configured Tower from the bottom up it makes sense to do this via awx in a scripted way - especially when Ansible is not yet set up properly.\nIn the first step you will learn to setup the inventory with awx step by step to get practice using the tool. For the following steps (Projects, Credentials, Job Templates) we will not go into such detail. Instead we will just explain the actual awx commands and put them all into a shell script. This shell script will serve as an example of how to bootstrap a Tower from bottom up.\nCreate an Inventory First we create a static inventory, we’ll get to dynamic inventories later on. Try to figure out the proper invocation of awx yourself and create an inventory name Example Inventory.\nRemember how you used the awx help to get down to the needed command.\n Click here for Solution   [student@ansible-1 ~]$ awx -f human inventory create --name \u0026#34;Example Inventory\u0026#34; --organization \u0026#34;Default\u0026#34;  You can work with multiple organizations in Tower. In this lab we’ll work in the Default organization.\n   Add Hosts to the Inventory using awx Now that we have the empty inventory created, add your two managed hosts using their internal hostnames node1 and node2, again using awx.\nClick here for Solution   [student@ansible-1 ~]$ awx -f human host create --name \u0026#34;node1\u0026#34; --inventory \u0026#34;Example Inventory\u0026#34; [student@ansible-1 ~]$ awx -f human host create --name \u0026#34;node2\u0026#34; --inventory \u0026#34;Example Inventory\u0026#34; \n  Create script to contain this and all following awx commands As mentioned one of the purposes of awx is to use it to automatically configure more complex Tower setups. In such cases, multiple awx commands are put together in a script. We follow that practice in our example here, and create a shell script on the control host with all commands you have to run to bootstrap Tower. So in the next few paragraphs we describe the steps to do and describe the corresponding awx commands. But we will not execute them, but instead write them into a script.\nIn code-server create a new file File-\u0026gt;New File and save it (File-\u0026gt;Save As) as setup-tower.sh. Add the commands executed above:\n#!/bin/bash awx -f human inventory create --name \u0026#34;Example Inventory\u0026#34; --organization \u0026#34;Default\u0026#34; awx -f human host create --name \u0026#34;node1\u0026#34; \\  --inventory \u0026#34;Example Inventory\u0026#34; awx -f human host create --name \u0026#34;node2\u0026#34; \\  --inventory \u0026#34;Example Inventory\u0026#34;  You have run these commands above already, true. But we want to show how to create the full script here. You\u0026rsquo;ll get \u0026ldquo;Duplicate\u0026rdquo; messages because the objects already exist.\n Next, save the script and make the script executable in the terminal window. Then launch it:\n[student@ansible-1 ~]$ chmod u+x /home/student\u0026lt;N\u0026gt;/setup-tower.sh [student@ansible-1 ~]$ /home/student\u0026lt;N\u0026gt;/setup-tower.sh From now on we’ll explain the needed commands for each of the next steps and add them to the script one-by-one.\nCreate Machine Credentials SSH keys have already been created and distributed in your lab environment and sudo has been setup on the managed hosts to allow password-less login. When you SSH into a host as user student\u0026lt;N\u0026gt; from ansible-1 you will become user ec2-user on the host you logged in.\n Now we want to configure these credentials to access our managed hosts from Tower. Add the following to to setup-tower.sh, but don’t run the script yet:\nawx -f human credential create --name \u0026quot;Example Credentials\u0026quot; \\ --organization \u0026quot;Default\u0026quot; \\ --credential_type \u0026quot;Machine\u0026quot; \\ --inputs '{\u0026quot;username\u0026quot;: \u0026quot;ec2-user\u0026quot;, \u0026quot;ssh_key_data\u0026quot;: \u0026quot;@~/.ssh/aws-private.pem\u0026quot;}'  Don’t run the shell script yet, first go through the following steps to add all commands to it.\nAs the awx commands get longer you’ll find we use the back-slash for line wraps to make the commands readable. You can copy the examples or use them without the \\ in one line, of course.\n Create the Project The Ansible content used in this lab is hosted on Github. The next step is to add a project to import the playbooks. Add the appropriate awx command to the script setup-tower.sh:\nawx -f human project create --name=\u0026quot;Apache\u0026quot; \\ --scm_type=git \\ --scm_url=\u0026quot;https://github.com/lj020326/ansible-labs-playbooks.git\u0026quot; \\ --organization \u0026quot;Default\u0026quot; \\ --scm_clean=true --scm_delete_on_update=true --scm_update_on_launch=true \\ --wait  Note that the first parameter to awx is different here since we work on the resource project.\n Create a Job Template Before running an Ansible Job from your Tower cluster you must create a Job Template, again business as usual for Tower users. Here awx will work on the resource job_template. Add the following command to your script setup-tower.sh. Don’t run the script yet.\nawx -f human job_templates create \\ --name=\u0026quot;Install Apache\u0026quot; \\ --inventory=\u0026quot;Example Inventory\u0026quot; \\ --project=Apache \\ --playbook=apache_install.yml \\ --become_enabled=\u0026quot;yes\u0026quot;  Attach Credentials to Job Template And finally we need to attach the credentials we created above to the Job Template. Add the following command to your script setup-tower.sh. Don’t run the script yet.\nawx -f human job_template associate --name \u0026quot;Install Apache\u0026quot; \\ --credential \u0026quot;Example Credentials\u0026quot;  Review the final script and execute it Verify that your script has all the pieces needed to properly configure Tower:\n  inventory with hosts\n  machine credentials and credentials for Git\n  project\n  job template\n  The final script is also shown here:\n#!/bin/bash awx -f human inventory create --name \u0026quot;Example Inventory\u0026quot; --organization \u0026quot;Default\u0026quot; awx -f human host create --name \u0026quot;node1\u0026quot; \\ --inventory \u0026quot;Example Inventory\u0026quot; awx -f human host create --name \u0026quot;node2\u0026quot; \\ --inventory \u0026quot;Example Inventory\u0026quot; awx -f human credential create --name \u0026quot;Example Credentials\u0026quot; \\ --organization \u0026quot;Default\u0026quot; \\ --credential_type \u0026quot;Machine\u0026quot; \\ --inputs '{\u0026quot;username\u0026quot;: \u0026quot;ec2-user\u0026quot;, \u0026quot;ssh_key_data\u0026quot;: \u0026quot;@~/.ssh/aws-private.pem\u0026quot;}' awx -f human project create --name=\u0026quot;Apache\u0026quot; \\ --scm_type=git \\ --scm_url=\u0026quot;https://github.com/lj020326/ansible-labs-playbooks.git\u0026quot; \\ --organization \u0026quot;Default\u0026quot; \\ --scm_clean=true --scm_delete_on_update=true --scm_update_on_launch=true \\ --wait awx -f human job_templates create \\ --name=\u0026quot;Install Apache\u0026quot; \\ --inventory=\u0026quot;Example Inventory\u0026quot; \\ --project=Apache \\ --playbook=apache_install.yml \\ --become_enabled=\u0026quot;yes\u0026quot; awx -f human job_template associate --name \u0026quot;Install Apache\u0026quot; \\ --credential \u0026quot;Example Credentials\u0026quot;  And now: Run the script (make sure the TOWER_ environment variables are defined), and verify that all resources were properly created in the web UI.\nTake away It’s easy to script Tower’s configuration using awx. This way you can bootstrap a new Tower node or script tasks you have to run on a regular basis. You will learn more about the Tower API at the end of the lab.\nIt’s a Cluster After All We are working in a clustered environment. To verify that the resources were created on all instances properly, login to the other Tower nodes web UI\u0026rsquo;s (You run the awx commands against your Tower node 1).\nHave a look around, everything we automatically configured on one Tower instance with our script was synchronized automatically to the other nodes. Inventory, credentials, projects, templates, all there.\n"
},
{
	"uri": "https://lj020326.github.io/ansible-tower-getting-started/4-surveys/",
	"title": "Surveys",
	"tags": [],
	"description": "",
	"content": "You might have noticed the ADD SURVEY button in the Template configuration view. A survey is a way to create a simple form to ask for parameters that get used as variables when a Template is launched as a Job.\nYou have installed Apache on all hosts in the job you just run. Now we’re going to extend on this:\n  Use a proper role which has a Jinja2 template to deploy an index.html file.\n  Create a job Template with a survey to collect the values for the index.html template.\n  Launch the job Template\n  Additionally, the role will also make sure that the Apache configuration is properly set up - in case it got mixed up during the other exercises.\nThe survey feature only provides a simple query for data - it does not support four-eye principles, queries based on dynamic data or nested menus.\n The Apache-configuration Role The Playbook and the role with the Jinja template already exist in the Github repository https://github.com/ansible/workshop-examples (always using the correct tag/branch) in the directory rhel/apache.\nHead over to the Github UI and have a look at the content: the playbook apache_role_install.yml merely references the role. The role can be found in the roles/role_apache subdirectory.\n  Inside the role, note the two variables in the templates/index.html.j2 template file marked by {{…​}}.\n  Also, check out the tasks in tasks/main.yml that deploy the file from the template.\n  What is this Playbook doing? It creates a file (dest) on the managed hosts from the template (src).\nThe role also deploys a static configuration for Apache. This is to make sure that all changes done in the previous chapters are overwritten and your examples work properly.\nBecause the Playbook and role is located in the same Github repo as the apache_install.yml Playbook you don\u0026rsquo;t have to configure a new project for this exercise.\nCreate a Template with a Survey Now you create a new Template that includes a survey.\nCreate Template   Go to Templates, click the button and choose Job Template\n  NAME: Create index.html\n  Configure the template to:\n  Use the Webserver Inventory\n  Use the Ansible Workshop Examples Project\n  Use the apache_role_install.yml Playbook\n  Use the Workshop Credentials\n  To run with privilege escalation\n    Try for yourself, the solution is below.\nClick here for Solution     NAME: Create index.html\n  JOB TYPE: Run\n  INVENTORY: Webserver\n  PROJECT: Ansible Workshop Examples\n  PLAYBOOK: rhel/apache/apache_role_install.yml\n  CREDENTIAL: Workshop Credentials\n  OPTIONS: Enable Privilege Escalation\n  Click SAVE\n    Do not run the template yet!\n Add the Survey   In the Template, click the ADD SURVEY button (you have to save the job template to make the button active!)\n  Under ADD SURVEY PROMPT fill in:\n  PROMPT: First Line\n  ANSWER VARIABLE NAME: first_line\n  ANSWER TYPE: Text\n    Click +ADD\n  In the same way add a second Survey Prompt\n  PROMPT: Second Line\n  ANSWER VARIABLE NAME: second_line\n  ANSWER TYPE: Text\n    Click +ADD\n  Click SAVE for the Survey\n  Click SAVE for the Template\n  Launch the Template Now launch the Create index.html job template.\nBefore the actual launch the survey will ask for First Line and Second Line. Fill in some text and click Next. The next window shows the values, if all is good run the Job by clicking Launch.\nNote how the two survey lines are shown to the left of the Job view as Extra Variables.\n After the job has completed, check the Apache homepage. In your code-server terminal, execute curl against node1:\n[student@ansible-1 ~]$ curl http://node1 \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Apache is running fine\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;This is survey field \u0026#34;First Line\u0026#34;: line one\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;This is survey field \u0026#34;Second Line\u0026#34;: line two\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; Note how the two variables where used by the playbook to create the content of the index.html file.\nWhat About Some Practice? Here is a list of tasks:\nPlease make sure to finish these steps as the next chapter depends on it!\n   Take the inventory Webserver and add node node2 to it.\n  Run the Create index.html Template again.\n  Verify the results on node2 by using curl.\n  "
},
{
	"uri": "https://lj020326.github.io/ansible-getting-started/4-variables/",
	"title": "Using Variables",
	"tags": [],
	"description": "",
	"content": "Previous exercises showed you the basics of Ansible Engine. In the next few exercises, we are going to teach some more advanced Ansible skills that will add flexibility and power to your playbooks.\nAnsible exists to make tasks simple and repeatable. We also know that not all systems are exactly alike and often require some slight change to the way an Ansible playbook is run. Enter variables.\nAnsible supports variables to store values that can be used in Playbooks. Variables can be defined in a variety of places and have a clear precedence. Ansible substitutes the variable with its value when a task is executed.\nVariables are referenced in Playbooks by placing the variable name in double curly braces:\nHere comes a variable {{ variable1 }} Variables and their values can be defined in various places: the inventory, additional files, on the command line, etc.\nThe recommended practice to provide variables in the inventory is to define them in files located in two directories named host_vars and group_vars:\n  To define variables for a group servers, a YAML file named group_vars/servers with the variable definitions is created.\n  To define variables specifically for a host node1, the file host_vars/node1 with the variable definitions is created.\n  Host variables take precedence over group variables (more about precedence can be found in the docs).\n Create Variable Files For understanding and practice let’s do a lab. Following up on the theme \u0026ldquo;Let’s build a webserver. Or two. Or even more…​\u0026rdquo;, you will change the index.html to show the development environment (dev/prod) a server is deployed in.\nOn the ansible control host, as the student user, create the directories to hold the variable definitions in ~/ansible-files/:\n[student@ansible-1 ansible-files]$ mkdir host_vars group_vars Now create two files containing variable definitions. We’ll define a variable named stage which will point to different environments, dev or prod:\n Create the file ~/ansible-files/group_vars/web with this content:  --- stage: dev  Create the file ~/ansible-files/host_vars/node2 with this content:  --- stage: prod What is this about?\n  For all servers in the web group the variable stage with value dev is defined. So as default we flag them as members of the dev environment.\n  For server node2 this is overridden and the host is flagged as a production server.\n  Create index.html Files Now create two files in ~/ansible-files/:\nOne called prod_index.html with the following content:\n\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a production webserver, take care!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; And the other called dev_index.html with the following content:\n\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a development webserver, have fun!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; Create the Playbook Now you need a Playbook that copies the prod or dev index.html file - according to the \u0026ldquo;stage\u0026rdquo; variable.\nCreate a new Playbook called deploy_index_html.yml in the ~/ansible-files/ directory.\nNote how the variable \u0026ldquo;stage\u0026rdquo; is used in the name of the file to copy.\n --- - name: Copy index.html hosts: web become: yes tasks: - name: copy index.html copy: src: ~/ansible-files/{{ stage }}_index.html dest: /var/www/html/index.html  Run the Playbook:  [student@ansible-1 ansible-files]$ ansible-playbook deploy_index_html.yml Test the Result The Playbook should copy different files as index.html to the hosts, use curl to test it. Check the inventory again if you forgot the IP addresses of your nodes.\n[student@ansible-1 ansible-files]$ grep node ~/lab_inventory/hosts node1 ansible_host=11.22.33.44 node2 ansible_host=22.33.44.55 node3 ansible_host=33.44.55.66 [student@ansible-1 ansible-files]$ curl http://11.22.33.44 \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a development webserver, have fun!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; [student@ansible-1 ansible-files]$ curl http://22.33.44.55 \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a production webserver, take care!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; [student@ansible-1 ansible-files]$ curl http://33.44.55.66 \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a development webserver, have fun!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt;  If by now you think: There has to be a smarter way to change content in files…​ you are absolutely right. This lab was done to introduce variables, you are about to learn about templates in one of the next chapters.\n Ansible Facts Ansible facts are variables that are automatically discovered by Ansible from a managed host. Remember the \u0026ldquo;Gathering Facts\u0026rdquo; task listed in the output of each ansible-playbook execution? At that moment the facts are gathered for each managed node. Facts can also be pulled by the setup module. They contain useful information stored into variables that administrators can reuse.\nTo get an idea what facts Ansible collects by default, on your control node as your student user run:\n[student@ansible-1 ansible-files]$ ansible node1 -m setup This might be a bit too much, you can use filters to limit the output to certain facts, the expression is shell-style wildcard:\n[student@ansible-1 ansible-files]$ ansible node1 -m setup -a \u0026#39;filter=ansible_eth0\u0026#39; Or what about only looking for memory related facts:\n[student@ansible-1 ansible-files]$ ansible node1 -m setup -a \u0026#39;filter=ansible_*_mb\u0026#39; Challenge Lab: Facts  Try to find and print the distribution (Red Hat) of your managed hosts. On one line, please.  Use grep to find the fact, then apply a filter to only print this fact.\n Click here for Solution   [student@ansible-1 ansible-files]$ ansible node1 -m setup|grep distribution [student@ansible-1 ansible-files]$ ansible node1 -m setup -a \u0026#39;filter=ansible_distribution\u0026#39; -o \n  Using Facts in Playbooks Facts can be used in a Playbook like variables, using the proper naming, of course. Create this Playbook as facts.yml in the ~/ansible-files/ directory:\n--- - name: Output facts within a playbook hosts: all tasks: - name: Prints Ansible facts debug: msg: The default IPv4 address of {{ ansible_fqdn }} is {{ ansible_default_ipv4.address }}  The \u0026ldquo;debug\u0026rdquo; module is handy for e.g. debugging variables or expressions.\n Execute it to see how the facts are printed:\n[student@ansible-1 ansible-files]$ ansible-playbook facts.yml PLAY [Output facts within a playbook] ****************************************** TASK [Gathering Facts] ********************************************************* ok: [node3] ok: [node2] ok: [node1] ok: [ansible] TASK [Prints Ansible facts] **************************************************** ok: [node1] =\u0026gt; msg: The default IPv4 address of node1 is 172.16.190.143 ok: [node2] =\u0026gt; msg: The default IPv4 address of node2 is 172.16.30.170 ok: [node3] =\u0026gt; msg: The default IPv4 address of node3 is 172.16.140.196 ok: [ansible] =\u0026gt; msg: The default IPv4 address of ansible is 172.16.2.10 PLAY RECAP ********************************************************************* ansible : ok=2 changed=0 unreachable=0 failed=0 node1 : ok=2 changed=0 unreachable=0 failed=0 node2 : ok=2 changed=0 unreachable=0 failed=0 node3 : ok=2 changed=0 unreachable=0 failed=0 "
},
{
	"uri": "https://lj020326.github.io/ansible-getting-started/5-handlers/",
	"title": "Conditionals, Handlers and Loops",
	"tags": [],
	"description": "",
	"content": "Conditionals Ansible can use conditionals to execute tasks or plays when certain conditions are met.\nTo implement a conditional, the when statement must be used, followed by the condition to test. The condition is expressed using one of the available operators like e.g. for comparison:\n         == Compares two objects for equality.   != Compares two objects for inequality.   \u0026gt; true if the left hand side is greater than the right hand side.   \u0026gt;= true if the left hand side is greater or equal to the right hand side.   \u0026lt; true if the left hand side is lower than the right hand side.   \u0026lt;= true if the left hand side is lower or equal to the right hand side.    There are many options to control execution flow in Ansible. More examples of supported conditionals can be located here: http://jinja.pocoo.org/docs/dev/templates/#comparisons\nAs an example you would like to install an FTP server, but only on hosts that are in the ftpserver inventory group.\nTo do that, first edit the inventory to add another group, and place node2 in it. Make sure that the IP address of node2 is always the same when node2 is listed. Edit the inventory ~/lab_inventory/hosts to look like the following listing:\n[all:vars] ansible_user=student\u0026lt;N\u0026gt; ansible_ssh_pass=xxx ansible_port=22 [web] node1 ansible_host=11.22.33.44 node2 ansible_host=22.33.44.55 node3 ansible_host=33.44.55.66 [ftpserver] node2 ansible_host=22.33.44.55 [control] ansible ansible_host=44.55.66.77 Next create the file ftpserver.yml on your control host in the ~/ansible-files/ directory:\n--- - name: Install vsftpd on ftpservers hosts: all become: yes tasks: - name: Install FTP server when host in ftpserver group yum: name: vsftpd state: latest when: inventory_hostname in groups[\u0026quot;ftpserver\u0026quot;]  By now you should know how to run Ansible Playbooks, we’ll start to be less verbose in this guide. Go create and run it. :-)\n Run it and examine the output. The expected outcome: The task is skipped on node1, node3 and the ansible host (your control host) because they are not in the ftpserver group in your inventory file.\nTASK [Install FTP server when host in ftpserver group] ******************************************* skipping: [ansible] skipping: [node1] skipping: [node3] changed: [node2] Handlers Sometimes when a task does make a change to the system, an additional task or tasks may need to be run. For example, a change to a service’s configuration file may then require that the service be restarted so that the changed configuration takes effect.\nHere Ansible’s handlers come into play. Handlers can be seen as inactive tasks that only get triggered when explicitly invoked using the notify statement. Read more about them in the Ansible Handlers documentation.\nAs a an example, let’s write a Playbook that:\n  manages Apache’s configuration file httpd.conf on all hosts in the web group\n  restarts Apache when the file has changed\n  First we need the file Ansible will deploy, let’s just take the one from node1. Remember to replace the IP address shown in the listing below with the IP address from your individual node1.\n[student@ansible-1 ansible-files]$ scp 11.22.33.44:/etc/httpd/conf/httpd.conf ~/ansible-files/ httpd.conf Next, create the Playbook httpd_conf.yml. Make sure that you are in the directory ~/ansible-files.\n--- - name: manage httpd.conf hosts: web become: yes tasks: - name: Copy Apache configuration file copy: src: httpd.conf dest: /etc/httpd/conf/ notify: - restart_apache handlers: - name: restart_apache service: name: httpd state: restarted So what’s new here?\n  The notify section calls the handler only when the copy task actually changes the file. That way the service is only restarted if needed - and not each time the playbook is run.\n  The handlers section defines a task that is only run on notification.\n  Run the Playbook. We didn’t change anything in the file yet so there should not be any changed lines in the output and of course the handler shouldn’t have fired.\n Now change the Listen 80 line in httpd.conf to:  Listen 8080   Run the Playbook again. Now Ansible’s output should be a lot more interesting:\n  httpd.conf should have been copied over\n  The handler should have restarted Apache\n    Apache should now listen on port 8080. Easy enough to verify:\n[student@ansible-1 ansible-files]$ curl http://22.33.44.55 curl: (7) Failed connect to 22.33.44.55:80; Connection refused [student@ansible-1 ansible-files]$ curl http://22.33.44.55:8080 \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a production webserver, take care!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; Feel free to change the httpd.conf file again and run the Playbook.\nSimple Loops Loops enable us to repeat the same task over and over again. For example, lets say you want to create multiple users. By using an Ansible loop, you can do that in a single task. Loops can also iterate over more than just basic lists. For example, if you have a list of users with their corresponding group, loop can iterate over them as well. Find out more about loops in the Ansible Loops documentation.\nTo show the loops feature we will generate three new users on node1. For that, create the Playbook loop_users.yml in ~/ansible-files on your control node as your student user and run it. We will use the user module to generate the user accounts.\n--- - name: Ensure users hosts: node1 become: yes tasks: - name: Ensure three users are present user: name: \u0026quot;{{ item }}\u0026quot; state: present loop: - dev_user - qa_user - prod_user  Lines starting with a variable need to be quoted.\n Understand the playbook and the output:\n  The names are not provided to the user module directly. Instead, there is only a variable called {{ item }} for the parameter name.\n  The loop keyword lists the actual user names. Those replace the {{ item }} during the actual execution of the playbook.\n  During execution the task is only listed once, but there are three changes listed underneath it.\n  Loops over hashes As mentioned loops can also be over lists of hashes. Imagine that the users should be assigned to different additional groups:\n- username: dev_user groups: ftp - username: qa_user groups: ftp - username: prod_user groups: apache The user module has the optional parameter groups to list additional users. To reference items in a hash, the {{ item }} keyword needs to reference the subkey: {{ item.groups }} for example.\nLet\u0026rsquo;s rewrite the playbook to create the users with additional user rights:\n--- - name: Ensure users hosts: node1 become: yes tasks: - name: Ensure three users are present user: name: \u0026quot;{{ item.username }}\u0026quot; state: present groups: \u0026quot;{{ item.groups }}\u0026quot; loop: - { username: 'dev_user', groups: 'ftp' } - { username: 'qa_user', groups: 'ftp' } - { username: 'prod_user', groups: 'apache' } Check the output:\n Again the task is listed once, but three changes are listed. Each loop with its content is shown.  Verify that the user prod_user was indeed created on node1:\n[student@ansible-1 ansible-files]$ ansible node1 -m command -a \u0026#34;id dev_user\u0026#34; node1 | CHANGED | rc=0 \u0026gt;\u0026gt; uid=1002(dev_user) gid=1002(dev_user) groups=1002(dev_user),50(ftp) "
},
{
	"uri": "https://lj020326.github.io/ansible-collections/5-creating-collections/",
	"title": "Creating Collections",
	"tags": [],
	"description": "",
	"content": "In this exercise you will learn how to create your own custom collection.\nPreparing the exercise environment To keep the content of this exercise separated from the other exercises you\u0026rsquo;ve done, first create a directory in your lab named exercise-05 and cd into it. This directory will be used during the whole exercise. In your VSCode terminal, run the following commands:\n[student@ansible-1 ~]$ mkdir exercise-05 [student@ansible-1 ~]$ cd exercise-05 [student@ansible-1 exercise-05]$ This was covered already in this lab, but it\u0026rsquo;s important enough to state again: Ansible Collections have two default lookup paths that are searched.\n  User scoped path /home/\u0026lt;username\u0026gt;/.ansible/collections\n  System scoped path /usr/share/ansible/collections\n  Users can customize the collections path by modifying the collections_path key in the ansible.cfg file or by setting the environment variable ANSIBLE_COLLECTIONS_PATHS with the desired search path.\n Inspecting the structure of a collection Ansible Collections have a standard directory and file structure that can hold modules, plugins, roles and playbooks.\ncollection/ ├── docs/ ├── galaxy.yml ├── plugins/ │ ├── modules/ │ │ └── module1.py │ ├── inventory/ │ └── .../ ├── README.md ├── roles/ │ ├── role1/ │ ├── role2/ │ └── .../ ├── playbooks/ └── tests/ Here is a short description of the collection structure:\n  The plugins folder holds plugins, modules, and module_utils that can be reused in playbooks and roles.\n  The roles folder hosts custom roles, while all collection playbooks must be stored in the playbooks folder.\n  The docs folder can be used for the collections documentation, as well as the main README.md file that is used to describe the collection and its content.\n  The tests folder holds tests written for the collection.\n  The galaxy.yml file is a YAML text file that contains all the metadata used in the Ansible Galaxy hub to index the collection. It is also used to list collection dependencies, if there are any.\n  Creating a Collection Okay, with the introduction out of the way, let\u0026rsquo;s create a custom collection and populate it with roles, playbook, plugins and modules. A scaffold for a user defined custom collection can be created manually or with the ansible-galaxy collection init command.\nCreate the Structure Let\u0026rsquo;s get started, in your VSCode terminal create the initial structure for your new collection:\n[student@ansible-1 exercise-05]$ ansible-galaxy collection init --init-path ansible_collections redhat.workshop_demo_collection - Collection redhat.workshop_demo_collection was created successfully The --init-path flag is used to define a custom path in which the skeleton will be initialized. The collection name always follows the pattern \u0026lt;namespace\u0026gt;.\u0026lt;collection\u0026gt;. The above example creates the workshop_demo_collection in the redhat namespace.\nHave a look for yourself:\n[student@ansible-1 exercise-05]$ tree . └── ansible_collections └── redhat └── workshop_demo_collection ├── docs ├── galaxy.yml ├── plugins │ └── README.md ├── README.md └── roles You can see the namespace directory was created together with a top-level ansible_collections directory. The scaffold is pretty minimal, note the template README files and a template galaxy.yml file is created to define Galaxy metadata.\nAdding Content: Custom Modules and Plugins Now it\u0026rsquo;s time to add content to our collection scaffold. Collections can include different kinds of plugins and modules. For a complete list of types please refer to the README.md file in the plugins folder.\nIn this lab we are going to create a minimal Hello World module and install it in the plugins/modules directory.\nFirst, create the plugins/modules directory:\n[student@ansible-1 exercise-05]$ cd ansible_collections/redhat/workshop_demo_collection [student@ansible-1 workshop_demo_collection}} ]$ mkdir plugins/modules Using the VSCode editor, create the file demo_hello.py with the content below in the modules folder. The demo_hello module says, well, \u0026ldquo;Hello\u0026rdquo; in different languages to a user defined through a parameter. This is not a lab about writing plugins, but take the time to look at the module code and understand its behavior.\nWhen doing copy/paste from your browser into the VSCode editor you might have to use Shift-Ctrl-V.\n #!/usr/bin/python  ANSIBLE_METADATA = { \u0026#39;metadata_version\u0026#39;: \u0026#39;1.0\u0026#39;, \u0026#39;status\u0026#39;: [\u0026#39;preview\u0026#39;], \u0026#39;supported_by\u0026#39;: \u0026#39;community\u0026#39; } DOCUMENTATION = \u0026#39;\u0026#39;\u0026#39; --- module: demo_hello short_description: A module that says hello in many languages version_added: \u0026#34;2.8\u0026#34; description: - \u0026#34;A module that says hello in many languages.\u0026#34; options: name: description: - Name of the person to salute. If no value is provided the default value will be used. required: false type: str default: John Doe author: - Gianni Salinetti (@giannisalinetti) \u0026#39;\u0026#39;\u0026#39; EXAMPLES = \u0026#39;\u0026#39;\u0026#39; # Pass in a custom name - name: Say hello to Linus Torvalds demo_hello: name: \u0026#34;Linus Torvalds\u0026#34; \u0026#39;\u0026#39;\u0026#39; RETURN = \u0026#39;\u0026#39;\u0026#39; fact: description: Hello string type: str sample: Hello John Doe! \u0026#39;\u0026#39;\u0026#39; import random from ansible.module_utils.basic import AnsibleModule FACTS = [ \u0026#34;Hello {name}!\u0026#34;, \u0026#34;Bonjour {name}!\u0026#34;, \u0026#34;Hola {name}!\u0026#34;, \u0026#34;Ciao {name}!\u0026#34;, \u0026#34;Hallo {name}!\u0026#34;, \u0026#34;Hei {name}!\u0026#34;, ] def run_module(): module_args = dict( name=dict(type=\u0026#39;str\u0026#39;, default=\u0026#39;John Doe\u0026#39;), ) module = AnsibleModule( argument_spec=module_args, supports_check_mode=True ) result = dict( changed=False, fact=\u0026#39;\u0026#39; ) result[\u0026#39;fact\u0026#39;] = random.choice(FACTS).format( name=module.params[\u0026#39;name\u0026#39;] ) if module.check_mode: return result module.exit_json(**result) def main(): run_module() if __name__ == \u0026#39;__main__\u0026#39;: main() An Ansible module is basically an implementation of the AnsibleModule class created and executed in a minimal function called run_module(). As you can see, a module has a main() function, like a plain Python executable. Anyway, it is not meant to be executed independently.\nAdding Content: Adding a Custom Role Ansible Collections are about bundling content that belongs together. So in the last step of this exercise we\u0026rsquo;ll create a role inside the custom collection that utilizes the new module. To make things easy it will simply write the greeting into the Message of the Day file /etc/motd.\nGenerate the new role hello_motd using the ansible-galaxy init command:\nThe ansible-galaxy command can be used to create initial directory structures for collections and roles. Make sure you are in the root directory of your ansible collection before executing this command.\n [student@ansible-1 workshop_demo_collection ]$ ansible-galaxy init --init-path roles hello_motd - Role hello_motd was created successfully In the next step add the following role tasks in the roles/hello_motd/tasks/main.yml file:\n--- # tasks file for hello_motd - name: Generate greeting and store result demo_hello: name: \u0026quot;{{ friend_name }}\u0026quot; register: demo_greeting - name: store test in /etc/motd copy: content: \u0026quot;{{ demo_greeting.fact }}\\n\u0026quot; dest: /etc/motd become: yes Notice the usage of the demo_hello module, installed in the collection, to generate the greeting string.\nWhen a collection role calls a module in the same collection namespace, the module is automatically resolved.\n Every role should come with sensible defaults, add the following default variable to the roles/hello_motd/defaults/main.yml file to make it look like this:\n--- # defaults file for hello_motd friend_name: \u0026quot;John Doe\u0026quot; Because ansible-galaxy creates a complete structure of directories and files, it\u0026rsquo;s a good idea to clean up unused ones to keep it tidy:\n[student@ansible-1 workshop_demo_collection ]$ rm -rf roles/hello_motd/{handlers,vars,tests} And as the final step customize the roles/hello_motd/meta/main.yml file to define Galaxy metadata and potential dependencies of the role. Use this sample minimal content:\ngalaxy_info: author: Ansible Workshop Team description: Hello world demo license: GPL-2.0-or-later min_ansible_version: 2.9 galaxy_tags: [\u0026quot;demo\u0026quot;] dependencies: [] Build and Install your Custom Collection Okay, you are done with creating your role. Now you\u0026rsquo;ll build the collection and generate a .tar.gz file that can be installed locally or uploaded to Galaxy. From the collection folder run the following command:\n[student@ansible-1 workshop_demo_collection ]$ ansible-galaxy collection build Created collection for redhat.workshop_demo_collection at /home/student\u0026lt;N\u0026gt;/exercise-05/ansible_collections/redhat/workshop_demo_collection/redhat-workshop_demo_collection-1.0.0.tar.gz The above command will create the file redhat-workshop_demo_collection-1.0.0.tar.gz. Notice the semantic x.y.z versioning. Once created the file can be installed in the COLLECTIONS_PATH to be tested locally:\n[student@ansible-1 workshop_demo_collection ]$ ansible-galaxy collection install redhat-workshop_demo_collection-1.0.0.tar.gz Process install dependency map Starting collection install process Installing \u0026#39;redhat.workshop_demo_collection:1.0.0\u0026#39; to \u0026#39;/home/student\u0026lt;N\u0026gt;/.ansible/collections/ansible_collections/redhat/workshop_demo_collection\u0026#39; By default the collection will be installed in the ~/.ansible/collections/ansible_collections folder. Now the collection can be used locally!\nTesting your Collection Create the exercise-05/collections_test folder to hold the local test:\n[student@ansible-1 workshop_demo_collection ]$ cd ~/exercise-05 [student@ansible-1 exercise-05 ]$ mkdir collections_test [student@ansible-1 exercise-05 ]$ cd collections_test To test the collection you need a basic playbook.yml file, create it with the following content:\n--- - hosts: localhost tasks: - import_role: name: redhat.workshop_demo_collection.hello_motd vars: friend_name: \u0026quot;Angry Potato\u0026quot; Running the Test Playbook Run the test playbook.\n[student@ansible-1 collections_test ]$ ansible-playbook playbook.yml PLAY [localhost] ****************************************************************************************************** TASK [Gathering Facts] ************************************************************************************************ ok: [localhost] TASK [redhat.workshop_demo_collection.hello_motd : Generate greeting and store result] ******************************** ok: [localhost] TASK [redhat.workshop_demo_collection.hello_motd : store test in /etc/motd] ******************************************* changed: [localhost] PLAY RECAP ************************************************************************************************************ localhost : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Verify the result by viewing the content of /etc/motd:\n[student@ansible-1 collections_test ]$ cat /etc/motd Hello Angry Potato!  The Module is creating the text in a random language, so your greeting might differ from the example above.\n Takeaways   Collections can be created using the ansible-galaxy collection init command. Users can develop collections contents accordingly to their needs and business logic.\n  Collections plugins can be either any kind of Ansible plugins or modules. Modules are developed inside collection to create an autonomous lifecycle from the main Ansible upstream.\n  Collection roles can use local collections plugins and modules.\n  "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-getting-started/5-rbac/",
	"title": "Role-based access control",
	"tags": [],
	"description": "",
	"content": "You have already learned how Tower separates credentials from users. Another advantage of Ansible Tower is the user and group rights management.\nAnsible Tower Users There are three types of Tower Users:\n  Normal User: Have read and write access limited to the inventory and projects for which that user has been granted the appropriate roles and privileges.\n  System Auditor: Auditors implicitly inherit the read-only capability for all objects within the Tower environment.\n  System Administrator: Has admin, read, and write privileges over the entire Tower installation.\n  Let’s create a user:\n  In the Tower menu under ACCESS click Users\n  Click the green plus button\n  Fill in the values for the new user:\n  FIRST NAME: Werner\n  LAST NAME: Web\n  EMAIL: wweb@example.com\n  USERNAME: wweb\n  PASSWORD: ansible\n  Confirm password\n  USER TYPE: Normal User\n    Click SAVE\n  Ansible Tower Teams A Team is a subdivision of an organization with associated users, projects, credentials, and permissions. Teams provide a means to implement role-based access control schemes and delegate responsibilities across organizations. For instance, permissions may be granted to a whole Team rather than each user on the Team.\nCreate a Team:\n  In the menu go to ACCESS → Teams\n  Click the green plus button and create a team named Web Content.\n  Click SAVE\n  Now you can add a user to the Team:\n  Switch to the Users view of the Web Content Team by clicking the USERS button.\n  Click the green plus button, check the box next to the wweb user and click SAVE.\n  Now click the PERMISSIONS button in the TEAMS view, you will be greeted with \u0026ldquo;No Permissions Have Been Granted\u0026rdquo;.\nPermissions allow to read, modify, and administer projects, inventories, and other Tower elements. Permissions can be set for different resources.\nGranting Permissions To allow users or teams to actually do something, you have to set permissions. The user wweb should only be allowed to modify content of the assigned webservers.\nAdd the permission to use the template:\n  In the Permissions view of the Team Web Content click the green plus button to add permissions.\n  A new window opens. You can choose to set permissions for a number of resources.\n  Select the resource type JOB TEMPLATES\n  Choose the Create index.html Template by checking the box next to it.\n    The second part of the window opens, here you assign roles to the selected resource.\n Choose EXECUTE    Click SAVE\n  Test Permissions Now log out of Tower’s web UI and in again as the wweb user.\n  Go to the Templates view, you should notice for wweb only the Create index.html template is listed. He is allowed to view and launch, but not to edit the Template. Just open the template and try to change it.\n  Run the Job Template by clicking the rocket icon. Enter the survey content to your liking and launch the job.\n  In the following Jobs view have a good look around, note that there where changes to the host (of course…​).\n  Check the result: In the code-server terminal execute curl to pull the content of the webserver on node1 (you could of course check node2, too):\n[student@ansible-1 ~]$ curl http://node1   In the web UI, log out user wweb and in again as admin.  Just recall what you have just done: You enabled a restricted user to run an Ansible Playbook\n  Without having access to the credentials\n  Without being able to change the Playbook itself\n  But with the ability to change variables you predefined!\n  Effectively you provided the power to execute automation to another user without handing out your credentials or giving the user the ability to change the automation code. And yet, at the same time the user can still modify things based on the surveys you created.\nThis capability is one of the main strengths of Ansible Tower!\n"
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/5-tower-cluster-jobs/",
	"title": "Run a Job in a Cluster",
	"tags": [],
	"description": "",
	"content": "After boot-strapping the Tower configuration from bottom up you are ready to start a job in your Tower cluster. In one of your Tower nodes web UI’s:\n  Open the Templates view\n  Look for the Install Apache Template you created with the script\n  Run it by clicking the rocket icon.\n  At first this is not different from a standard Tower setup. But as this is a cluster of active Tower instances every instance could have run the job.\nSo, which Instance did actually run the Job? There are a couple of ways to find the node that executed the job.\nFrom the Job Output The most obvious way is to look up the EXECUTION NODE in the details of the job output. If you closed it already or want to look it up later, go to VIEWS-\u0026gt;Jobs and look up the job in question.\nFrom the instance groups In one of the Tower instances web UI under ADMINISTRATION go to the Instance Groups view. For the tower instance group, the TOTAL JOBS counter shows the number of finished jobs. If you click TOTAL JOBS you’ll get a detailed list of jobs.\nTo see on what instance a job actually run go back to the Instance Groups view. If you click INSTANCES under the tower group, you will get an overview of the TOTAL JOBS each Tower instance in this group executed. Clicking TOTAL JOBS for an instance leads to a detailed job list for this instance.\nUsing the API   First find the job ID: In the web UI access VIEWS→Jobs\n  The jobs names are prefixed with the job ID, example 3 - Install Apache\n  Make sure you choose a job with type \u0026ldquo;Playbook run\u0026rdquo;.\n  With the ID you can query the API for the instance/node the job was executed on  Bring up the terminal in your VSCode session and run:\nReplace \u0026lt;ID\u0026gt; with the job ID you want to query and VERY_SECRET_PASSWORD with your actual password from the landing page.\n [student@ansible-1 ~]$ curl -s -k -u admin:VERY_SECRET_PASSWORD https://ansible-1/api/v2/jobs/\u0026lt;ID\u0026gt;/ | python3 -m json.tool | grep execution_node \u0026#34;execution_node\u0026#34;: \u0026#34;ansible-1\u0026#34;,  You can use any method you want to access the API and to display the result, of course. The usage of curl and python was just an example.\n Via API in the browser Another way to query the Tower API is using a browser. For example to have a look at the job details (basically what you did above using curl and friends):\nNote you used the internal hostname above, when using your browser, you have to use the external hostname, of course.\n   Find the job ID\n  Now get the job details via the API interface:\n  Login to the API with user admin and password VERY_SECRET_PASSWORD: https://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com/api/\n  Open the URL https://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com/api/v2/jobs/\u0026lt;ID\u0026gt;/ where \u0026lt;ID\u0026gt; is the number of the job you just looked up in the UI.\n  Search the page for the string you are interested in, e.g. execution_node\n    You can of course query any Tower node.\n "
},
{
	"uri": "https://lj020326.github.io/ansible-getting-started/6-templates/",
	"title": "Templates",
	"tags": [],
	"description": "",
	"content": "Ansible uses Jinja2 templating to modify files before they are distributed to managed hosts. Jinja2 is one of the most used templating engines for Python.\nUsing Templates in Playbooks When a template for a file has been created, it can be deployed to the managed hosts using the template module, which supports the transfer of a local file from the control node to the managed hosts.\nAs an example of using templates you will change the motd file to contain host-specific data.\nFirst in the ~/ansible-files/ directory create the template file motd-facts.j2:\nWelcome to {{ ansible_hostname }}. {{ ansible_distribution }} {{ ansible_distribution_version}} deployed on {{ ansible_architecture }} architecture. The template file contains the basic text that will later be copied over. It also contains variables which will be replaced on the target machines individually.\nNext we need a playbook to use this template. In the ~/ansible-files/ directory create the Playbook motd-facts.yml:\n--- - name: Fill motd file with host data hosts: node1 become: yes tasks: - template: src: motd-facts.j2 dest: /etc/motd owner: root group: root mode: 0644 You have done this a couple of times by now:\n  Understand what the Playbook does.\n  Execute the Playbook motd-facts.yml.\n  Login to node1 via SSH and check the message of the day content.\n  Log out of node1.\n  You should see how Ansible replaces the variables with the facts it discovered from the system.\nChallenge Lab Add a line to the template to list the current kernel of the managed node.\n Find a fact that contains the kernel version using the commands you learned in the \u0026ldquo;Ansible Facts\u0026rdquo; chapter.  Do a grep -i for kernel\n   Change the template to use the fact you found.\n  Run the Playbook again.\n  Check motd by logging in to node1\n   Click here for Solution     Find the fact:  [student@ansible-1 ansible-files]$ ansible node1 -m setup|grep -i kernel \u0026#34;ansible_kernel\u0026#34;: \u0026#34;3.10.0-693.el7.x86_64\u0026#34;,  Modify the template motd-facts.j2:  Welcome to {{ ansible_hostname }}. {{ ansible_distribution }} {{ ansible_distribution_version}} deployed on {{ ansible_architecture }} architecture running kernel {{ ansible_kernel }}.  Run the playbook. Verify the new message via SSH login to node1.    "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/6-instance-groups/",
	"title": "Tower Instance Groups",
	"tags": [],
	"description": "",
	"content": "Ansible Tower clustering allows you to easily add capacity to your Tower infrastructure by adding instances. In a single-group Tower cluster where all instances are within the tower group there is no way to influence which node will run a job, the cluster will take care of scheduling Jobs as it sees fit.\nTo enable more control over which node is running a job, Tower 3.2 saw the introduction of the Instance Groups feature. Instance groups allow you to organize your cluster nodes into groups. In turn Jobs can be assigned to Instance Groups by configuring the Groups in Organizations, Inventories or Job Templates.\nThe order of priority is Job Template \u0026gt; Inventory \u0026gt; Organization. So Instance Groups configured in Job Templates take precedence over those configured in Inventories, which take precedence over Organizations\n Some things to keep in mind about Instance Groups:\n  Nodes in an Instance Group share a job queue.\n  You can have as many Instance Groups as you like as long as there is at least one node in the tower group.\n  Nodes can be in one or more Instance Groups.\n  Groups can not be named instance_group_tower!\n  Tower instances can’t have the same name as a group.\n  Instance Groups allows some pretty cool setups, e.g. you could have some nodes shared over the whole cluster (by putting them into all groups) but then have other nodes that are dedicated to one group to reserve some capacity.\nThe base tower group does house keeping like processing events from jobs for all groups so the node count of this group has to scale with your overall cluster load, even if these nodes are not used to run Jobs.\n Talking about the tower group: As you have learned this group is crucial for the operations of a Tower cluster. Apart from the house keeping tasks, if a resource is not associated with an Instance Group, one of the nodes from the tower group will run the Job. So if there are no operational nodes in the base group, the cluster will not be able to run Jobs.\nIt is important to have enough nodes in the tower group\n There is a great blog post going into Instance Groups with a lot more depth.\n Instance Group Setup Having the introduction out of the way, let’s get back to our lab and give Instance Groups a try.\nIn a basic cluster setup like ours you just have the tower base group. So let’s go and setup two instance groups:\n  In the Instance Groups add a new group by clicking the green icon and then CREATE INSTANCE GROUP\n  Name the new group dev\n  SAVE\n  Click the INSTANCES button and add node ansible-2 again using the icon\n  Do the same to create a the new group prod with instance ansible-3\nGo back to the Instance Groups view, you should now have the following setup:\n  All instances are in the tower base group\n  Two more groups (prod and dev) with one instances each\n  We’re using the internal names of the Tower nodes here.\n This is not best practice, it’s just for the sake of this lab! Any jobs that are launched targeting a group without active nodes will be stuck in a waiting state until instances become available. So one-instance groups are never a good idea.\n Verify Instance Groups You can check your instance groups in a number of ways.\nVia the Web UI You have configured the groups here, open the URL\nhttps://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com/#/instance_groups  in your browser.\nIn the INSTANCE GROUPS overview all instance groups are listed with details of the group itself like number of instances in the group, running jobs and finished jobs. Like you’ve seen before the current capacity of the instance groups is shown in a live view, thus providing a quick insight if there are capacity problems.\nVia the awx CLI In your VSCode terminal, run:\n[student@ansible-1 ~]$ awx -k instance_group list -f human id name == ===== 1 tower 2 dev 3 prod  Via the API You can again query the API to get this information. Either use the browser to access the URL (you might have to login to the API again):\nhttps://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com/api/v2/instance_groups/\nor use curl to access the API from the command line in your VSCode terminal:\n[student@ansible-1 ~]$ curl -s -k -u admin:VERY_SECRET_PASSWORD https://ansible-1/api/v2/instance_groups/| python3 -m json.tool\nThe curl command has to be on one line. Do not forget or oversee the final slash at the end of the URL, it is relevant!\n Deactivating Tower Instances While in the INSTANCES GROUPS overview in the web UI click the INSTANCES link for, say, the dev group. In the next view you’ll see a slide button next to each Tower instance (only one in this case).\n  The button should be set to \u0026ldquo;checked\u0026rdquo; meaning \u0026ldquo;active\u0026rdquo;. Clicking it would deactivate the corresponding instance and would prevent that further jobs are assigned to it.\n  Running jobs on an instance which is set to \u0026ldquo;OFF\u0026rdquo; are finished in a normal way.\n  Further to the right a slider can change the amount of forks scheduled on an instance. This way it is possible to influence in which ratio the jobs are assigned.\n  "
},
{
	"uri": "https://lj020326.github.io/ansible-collections/6-automation-hub-and-galaxy/",
	"title": "Use Automation Hub",
	"tags": [],
	"description": "",
	"content": "Automation Hub and Ansible Galaxy Red Hat Automation Hub Automation Hub is a service that is provided as part of the Red Hat SaaS offering to subscribers of Ansible Automation Platform. It is a central location where supported and certified Ansible Content Collections by Red Hat and its Partners can be found, downloaded and integrated into your Ansible automation. The support for Automation Hub is included with Red Hat Automation Platform subscription.\nRed Hat Automation Hub resides on https://cloud.redhat.com/ansible/automation-hub and requires Red Hat customer portal credentials and a valid and active Red Hat Automation Platform subscription.\n Certified Content In the portal of Automation Hub, users have direct access to certified content collections from Red Hat and Partners. Certified collections are developed, tested, built, delivered, and supported by Red Hat and its Partners. To find more details about the scope of support, check the Ansible Certified Content FAQ,\nSupported Automation Automation Hub is a one-stop-shop for Ansible content that is backed by support from Red Hat to deliver additional reassurance for customers. Additional supportability claims for these collections may be provided under the \u0026ldquo;Maintained and Supported By\u0026rdquo; one of Red Hat Partners. A list of currently supported content can be found in the Knowledge base.\nAnsible Galaxy Ansible Galaxy is the upstream location for the Ansible community that initially started to provide pre-packaged units of work known as Ansible roles. Roles can be used from Ansible Playbooks and immediately put to work. in a recent version of Galaxy started to provide Ansible content collections as well.\nAnsible Galaxy resides on https://galaxy.ansible.com/\nAccessing collections from Automation Hub Ansible collections can be used and downloaded from multiple locations. They can either be downloaded using a requirement file, statically included in the git repository or eventually installed separately in the virtual environment.\nThis is not an exercise you can actually run in this environment because you would need to have an account to Ansible Automation Hub that comes with a subscription of Ansible Automation Platform. It is here for your information.\n Authenticate Ansible Tower to Automation Hub Creating a token Authenticating Ansible Tower requires a token. It can be achieved using the steps below:\n  Navigate to https://cloud.redhat.com/ansible/automation-hub/token/\n  Click Load Token.\n  Click copy icon to copy the API token to the clipboard.\n  Using authentication token   As user admin, navigate to the Settings l\u0026gt; Jobs\n  Set PRIMARY GALAXY SERVER URL to https://cloud.redhat.com/api/automation-hub/\n  Set PRIMARY GALAXY AUTHENTICATION URL to https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token\n  Set PRIMARY GALAXY SERVER TOKEN to \u0026lt;COPIED_TOKEN\u0026gt;\n  It is recommended using Red Hat Automation Hub as primary Galaxy Server URL to ensure using certified and supported content by Red Hat and its partners via Red Hat Ansible Automation subscription.\n Using collections After authenticating Ansible Tower to access Automation Hub, using a collections/requirements.yml file automatically fetches the content collections from Automation Hub as first source.\nTakeaways  Ansible Galaxy hosts upstream community content. The Red Hat Automation Hub provides certified collections that are supported by Red Hat and its Partners. It\u0026rsquo;s a service provided by the Red Hat Ansible Automation Platform Subscription. Red Hat Ansible Tower can be configured to authenticate to Red Hat Automation Hub in order to fetch certified and supported content collections that are utilized in a given project.  "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-getting-started/6-workflows/",
	"title": "Workflows",
	"tags": [],
	"description": "",
	"content": "Workflows were introduced as a major new feature in Ansible Tower 3.1. The basic idea of a workflow is to link multiple Job Templates together. They may or may not share inventory, Playbooks or even permissions. The links can be conditional:\n  if job template A succeeds, job template B is automatically executed afterwards\n  but in case of failure, job template C will be run.\n  And the workflows are not even limited to Job Templates, but can also include project or inventory updates.\nThis enables new applications for Tower: different Job Templates can build upon each other. E.g. the networking team creates playbooks with their own content, in their own Git repository and even targeting their own inventory, while the operations team also has their own repos, playbooks and inventory.\nIn this lab you’ll learn how to setup a workflow.\nLab Scenario You have two departments in your organization:\n  The web operations team that is developing Playbooks for deploying web infrastructures in their own Git repository.\n  The web applications team, that develops JavaScript web applications for NodeJS in their Git repository.\n  When there is a new NodeJS-based website to deploy, two main steps need to happen:\nThe web operations team has to:\n  Install and configure NodeJS to run as a service.\n  An Apache instance needs to be installed and configured as proxy to pass requests for the NodeJS content to the NodeJS backend. And a lot of other steps might be needed, too. Like SELinux, firewall\u0026hellip; you know the drill.\n  The web developer team has to:\n  Deploy the most recent version of the JavaScript web application.\n Make sure stuff like making sure the directory structure is fine and service restarts happen.    To make things somewhat easier for you, everything needed already exists in a Github repository: Playbooks, JavaScript files etc. You just need to glue it together.\nIn this example we use two different tags (each on its specific branch) of the same repository for the content of the separate teams. In reality the structure of your SCM repositories depends on a lot of factors and could be different.\n Set up Projects First you have to set up the Git repo as Projects like you normally would. You have done this before, try to do this on your own. Detailed instructions can be found below.\nIf you are still logged in as user wweb, log out of and log in as user admin again.\n   Create the project for web operations:\n  It should be named Webops Git Repo\n  The URL to access the repo is https://github.com/ansible/workshop-examples.git\n  The SCM BRANCH/TAG/COMMIT is webops_summit_2020\n  Do not allow branch overrides\n    Create the project for the application developers:\n  It should be named Webdev Git Repo\n  The URL to access the repo is https://github.com/ansible/workshop-examples.git\n  The SCM BRANCH/TAG/COMMIT is webdev_summit_2020\n  Do not allow branch overrides\n    Click here for Solution     Create the project for web operations. In the Projects view click the green us button and fill in:\n  NAME: Webops Git Repo\n  ORGANIZATION: Default\n  SCM TYPE: Git\n  SCM URL: https://github.com/ansible/workshop-examples.git\n  SCM BRANCH/TAG/COMMIT: webops_summit_2020\n  SCM UPDATE OPTIONS: Tick the first three boxes.\n    Click SAVE\n  Create the project for the application developers. In the Projects view click the green plus button and fill in:\n  NAME: Webdev Git Repo\n  ORGANIZATION: Default\n  SCM TYPE: Git\n  SCM URL: https://github.com/ansible/workshop-examples.git\n  SCM BRANCH/TAG/COMMIT: webdev_summit_2020\n  SCM UPDATE OPTIONS: Tick the first three boxes.\n    Click SAVE\n    Set up Job Templates Now you have to create Job Templates like you would for \u0026ldquo;normal\u0026rdquo; Jobs.\nWe want to install the NodeJS app on node3 only. The Inventory Workshop Inventory contains all nodes, but we can limit the nodes using the LIMIT field!\n   Go to the Templates view, click the green plus button and choose Job Template:\n  NAME: Web Infra Deploy\n  JOB TYPE: Run\n  INVENTORY: Workshop Inventory\n  PROJECT: Webops Git Repo\n  PLAYBOOK: rhel/webops/web_infrastructure.yml\n  CREDENTIAL: Workshop Credentials\n  LIMIT: node3\n  OPTIONS: Enable privilege escalation\n    Click SAVE\n  Go to the Templates view, click the green plus button and choose Job Template:\n  NAME: Web App Deploy\n  JOB TYPE: Run\n  INVENTORY: Workshop Inventory\n  PROJECT: Webdev Git Repo\n  PLAYBOOK: rhel/webdev/install_node_app.yml\n  CREDENTIALS: Workshop Credentials\n  LIMIT: node3\n  OPTIONS: Enable privilege escalation\n    Click SAVE\n  If you want to know what the Playbooks look like, check out the Github URL and switch to the appropriate branches.\n Set up the Workflow And now you finally set up the Workflow. Workflows are configured in the Templates view, you might have noticed you can choose between Job Template and Workflow Template when adding a template so this is finally making sense.\n  Go to the Templates view and click the the green plus button. This time choose Workflow Template\n  NAME: Deploy Webapplication\n  ORGANIZATION: Default\n    Click SAVE\n  After saving the template the Workflow Visualizer opens to allow you to build a workflow. You can later open the Workflow Visualizer again by using the button on the template details page.\n  Click on the START button, a new node opens. To the right under ADD A NODE you can assign an action to the node, you can choose between Template, Project Sync, Inventory Sync and Approval.\n  In this lab we’ll link Templates together, so select the Web Infra Deploy Template and click SELECT.\n  The node gets annotated with the name of the job. Hover the mouse pointer over the node, you’ll see a red x, a green + and a blue chain-symbol appear.\n  Using the red \u0026ldquo;x\u0026rdquo; allows you to remove the node, the green plus lets you add the next node and the chain-symbol links to another node.\n   Click the green + sign\n  Choose Web App Deploy as the next Job (you might have to switch to the next page)\n  Leave Run set to On Success\n  The type allows for more complex workflows. You could lay out different execution paths for successful and for failed Playbook runs.\n   Click SELECT\n  Click SAVE in the WORKFLOW VISUALIZER view\n  Click SAVE in the Workflow Template view\n  The Workflow Visualizer has options for setting up more advanced workflows, please refer to the documentation.\n And Action Your Deploy Webapplication workflow is ready to go, launch it.\n Click the blue LAUNCH button directly or go to the the Templates view and launch the Deploy Webapplication workflow by clicking the rocket icon.  Note how the workflow run is shown in the job view. In contrast to a normal job template job execution this time there is no Playbook output on the right, but a visual representation of the different workflow steps. If you want to look at the actual Jobs behind that, click DETAILS in each step. If you want to get back from a details view to the corresponding workflow, just hit your browsers back button.\nAfter the job has finished, check if everything worked fine. In your code-server terminal, run:\n[student@ansible-1 ~]$ curl http://node3/nodejs  You should be greeted with a friendly Hello World\n"
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/7-parallel-jobs/",
	"title": "Parallel Jobs",
	"tags": [],
	"description": "",
	"content": "The real power of instance groups is revealed when multiple jobs are started, and they are assigned to different Tower nodes. To launch parallel jobs we will set up a workflow with multiple concurrent jobs.\nLab Scenario To configure something meaningful we\u0026rsquo;ll make a quick detour into security automation here. During this lab we’ll focus on security compliance according to STIG, CIS and so on. Often these compliance rules are enforced by executing an Ansible task per each requirement. This makes documentation and audit easier.\nCompliance requirements are often grouped into independent categories. The tasks can often be executed in parallel because they do not conflict with each other.\nIn our demo case we use three playbooks which:\n  ensure the absence of a few packages (STIG)\n  ensure configuration of PAM and login cryptography (STIG)\n  ensure absence of services and kernel modules (CIS).\n  The Playbooks can be found in the Github repository you already setup as a Project in your Tower.\nPrepare the Compliance Lab Create three Templates As mentioned the Github repository contains three Playbooks to enforce different compliance requirements. First create these three templates and attach credentials using the awx CLI in the VSCode terminal:\n[student@ansible-1 ~]$ awx -f human job_template create --name \u0026quot;Compliance STIG packages\u0026quot; \\ --job-type run \\ --inventory \u0026quot;Example Inventory\u0026quot; \\ --project \u0026quot;Apache\u0026quot; \\ --playbook \u0026quot;stig-packages.yml\u0026quot; \\ --become_enabled 1 [student@ansible-1 ~]$ awx -f human job_template associate --name \u0026quot;Compliance STIG packages\u0026quot; \\ --credential \u0026quot;Example Credentials\u0026quot; [student@ansible-1 ~]$ awx -f human job_template create --name \u0026quot;Compliance STIG config\u0026quot; \\ --credential \u0026quot;Example Credentials\u0026quot; \\ --job_type run \\ --inventory \u0026quot;Example Inventory\u0026quot; \\ --project \u0026quot;Apache\u0026quot; \\ --playbook \u0026quot;stig-config.yml\u0026quot; \\ --become_enabled 1 [student@ansible-1 ~]$ awx -f human job_template associate --name \u0026quot;Compliance STIG config\u0026quot; \\ --credential \u0026quot;Example Credentials\u0026quot; [student@ansible-1 ~]$ awx -f human job_template create --name \u0026quot;Compliance CIS\u0026quot; \\ --job-type run \\ --inventory \u0026quot;Example Inventory\u0026quot; \\ --project \u0026quot;Apache\u0026quot; \\ --playbook \u0026quot;cis.yml\u0026quot; \\ --become_enabled 1 [student@ansible-1 ~]$ awx -f human job_template associate --name \u0026quot;Compliance CIS\u0026quot; \\ --credential \u0026quot;Example Credentials\u0026quot;  Create Parallel Workflow To enable parallel execution of the tasks in these job templates, we will create a workflow. We’ll use the web UI because using awx for this is a bit too involved for a lab. Workflows are configured in the Templates view, you might have noticed you can choose between Job Template and Workflow Template when adding a template.\n  Go to the Templates view and click the button. This time choose Workflow Template\n  NAME: Compliance Workflow\n  ORGANIZATION: Default - click on the magnifying glass if necessary\n  Click SAVE\n    Now the WORKFLOW VISUALIZER button becomes active and the graphical workflow designer opens.\n  Click on the START button, a new node opens. To the right you can assign an action to the node, you can choose between TEMPLATE, PROJECT SYNC, INVENTORY SYNC or APPROVAL.\n  In this lab we’ll link multiple jobs to the START, so select the Compliance STIG packages job template and click SELECT. The node gets annotated with the name of the job.\n  Click on the START button again, another new node opens.\n  Select the Compliance STIG config job template and click SELECT. The node gets annotated with the name of the job.\n  Click on the START button again, another new node opens.\n  Select the Compliance CIS job template and click SELECT. The node gets annotated with the name of the job.\n  Click SAVE\n  In the workflow overview window, again click SAVE\n  You have configured a Workflow that is not going through templates one after the other but rather executes three templates in parallel.\nExecute and Watch Your workflow is ready to go, launch it.\n  In the Templates view launch the Compliance Workflow by clicking the rocket icon.\n  Wait until the workflow has finished.\n  Go to the Instance Groups view and find out how the jobs where distributed over the instances:\n  Open the INSTANCES view of the tower instance group.\n  Look at the TOTAL JOBS view of the three instances\n  Because the Job Templates called in the workflow didn’t specify an instance group, they where distributed (more or less) evenly over the instances.\n  Deactivate a node Now deactivate instance ansible-1 with the slider button and wait until it is shown as unavailable. Make a (mental) note of the TOTAL JOBS counter of the instance. Go back to the list of templates and launch the workflow Compliance Workflow again.\nGo back to the Instance Groups view, get back to the instance overview of instance group tower and verify that the three Playbooks where launched on the remaining instances and the TOTAL JOBS counter of instance ansible-1 didn’t change.\nActivate ansible-1 again by sliding the button to \u0026ldquo;checked\u0026rdquo;.\nUsing Instance Groups So we have seen how a Tower cluster is distributing jobs over Tower instances by default. We have already created instance groups which allow us to take control over which job is executed on which node, so let’s use them.\nTo make it easier to spot where the jobs were run, let’s first empty the jobs history. This can be done using awx-manage on one of the Tower instances. From your VSCode terminal and as root run the command:\n[student@ansible-1 ~]$ sudo -i [root@ansible-1 ~]# awx-manage cleanup_jobs --days=0 deleting \u0026#34;2020-04-08 15:43:12.121133+00:00-2-failed\u0026#34; (2 host summaries, 8 events) [...] notifications: 0 deleted, 0 skipped. [ansible-1 ~]# exit Assign Jobs to Instance Groups One way to assign a job to an instance group is in the job template. As our compliance workflow uses three job templates, do this for all of them:\n  In the web UI, go to RESOURCES→Templates\n  Open one of the three compliance templates\n  In the Instance Groups field, choose the dev instance group and click SAVE.\n  Click SAVE again for the job template!\n  Do this for the other two compliance templates, too.\n  Now the jobs that make up our Compliance Workflow are all configured to run on the instances of the dev instance group.\nRun the Workflow You have done this a couple of times now, you should get along without detailed instructions.\n  Run the Compliance Workflow\n  What would you expect? On what instance(s) should the workflow jobs run?\n  Verify!\n  Result: The workflow and the associated jobs will run on ansible-2. Okay, big surprise, in the dev instance group there is only one instance.\n But what’s going to happen if you disable this instance?\n  Disable the ansible-2 instance in the Instance Groups view.\n  Run the workflow again.\n  What would you expect? On what instance(s) should the workflow jobs run?\n  Verify!\n  Result: The workflow is running but the associated jobs will stay in pending state because there are no instance available in the dev instance group, and the workflow runs \u0026ldquo;forever\u0026rdquo;.\n What’s going to happen if you enable the instance again?\n  Go to the Instance Groups view and enable ansible-2 again.\n  Check in the Jobs and Instance Groups view what’s happening.\n  Result: After the instance is enabled again the jobs will pickup and run on ansible-2.\n At this point make sure the instances you disabled in the previous steps are definitely enabled again! Otherwise subsequent lab tasks might fail…\n "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-getting-started/7-wrap/",
	"title": "Wrap up",
	"tags": [],
	"description": "",
	"content": "Final Challenge or Putting it all Together This is the final challenge where we try to put most of what you have learned together.\nLet’s set the stage Your operations team and your application development team like what they see in Tower. To really use it in their environment they put together these requirements:\n  All webservers (node1, node2 and node3) should go in one group.\n  As the webservers can be used for development purposes or in production, there has to be a way to flag them accordingly as \u0026ldquo;stage dev\u0026rdquo; or \u0026ldquo;stage prod\u0026rdquo;.\n Currently node1 and node3 should be used as a development systems and node2 in production.    Of course the content of the world famous application \u0026ldquo;index.html\u0026rdquo; will be different between dev and prod stages.\n  There should be a title on the page stating the environment.\n  There should be a content field.\n    The content writer wweb should have access to a survey to change the content for dev and prod servers.\n  The Git Repository All code is already in place - this is a Tower lab after all and not about configuring Apache. Check out the Ansible Workshop Examples git repository at https://github.com/ansible/workshop-examples (again with the correct tag or branch). There you will find the playbook webcontent.yml, which calls the role role_webcontent.\nCompared to the previous Apache installation role there is a major difference: there are now two versions of an index.html template, and a task deploying the template file which has a variable as part of the template file name.\nHere are the files for you to review (path is relative to the Github repository):\n rhel/apache/roles/role_webcontent/templates/dev_index.html.j2  \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a development webserver, have fun!\u0026lt;/h1\u0026gt; {{ dev_content }} \u0026lt;/body\u0026gt;  rhel/apache/roles/role_webcontent/templates/prod_index.html.j2  \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a production webserver, take care!\u0026lt;/h1\u0026gt; {{ prod_content }} \u0026lt;/body\u0026gt;  rhel/apache/roles/role_webcontent/tasks/main.yml  Only the part deploying the template is shown\n [...] - name: Deploy index.html from template template: src: \u0026quot;{{ stage }}_index.html.j2\u0026quot; dest: /var/www/html/index.html notify: apache-restart Prepare Inventory There is of course more then one way to accomplish this, but here is what you should do:\n  Make sure all hosts are in the inventory group Webserver.\n  Define a variable stage with the value dev for the Webserver inventory:\n Add stage: dev to the inventory Webserver by putting it into the VARIABLES field beneath the three start-yaml dashes. Click SAVE    Make sure to add the variable to the inventory and not to the new node3!\n  In the same way add a variable stage: prod but this time only for node2 (by clicking the hostname in the HOSTS view). Click SAVE  This way the host variable overrides the variable set at the Inventory level because it\u0026rsquo;s more specific and takes precedence.\nMake sure to keep the three dashes that mark the YAML start in place!\n Create the Template   Create a new Job Template named Create Web Content that\n  targets the Webserver inventory\n  uses the Playbook rhel/apache/webcontent.yml from the Ansible Workshop Examples Project\n  Defines two variables: dev_content: default dev content and prod_content: default prod content in the EXTRA VARIABLES FIELD\n  Uses Workshop Credentials and runs with privilege escalation.\n    Save and run the template.\n  Check the results This time we use the power of Ansible to check the results: execute curl to get the web content from each node, orchestrated by an ad hoc command on the command line of your code-server terminal:\nWe are using the ansible_host variable in the URL to access every node in the inventory group.\n [ansible-1 ~]$ ansible web -m command -a \u0026#34;curl -s http://{{ ansible_host }}\u0026#34; [WARNING]: Consider using the get_url or uri module rather than running \u0026#39;curl\u0026#39;. If you need to use command because get_url or uri is insufficient you can add \u0026#39;warn: false\u0026#39; to this command task or set \u0026#39;command_warnings=False\u0026#39; in ansible.cfg to get rid of this message. node2 | CHANGED | rc=0 \u0026gt;\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a production webserver, take care!\u0026lt;/h1\u0026gt; prod wweb \u0026lt;/body\u0026gt; node1 | CHANGED | rc=0 \u0026gt;\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a development webserver, have fun!\u0026lt;/h1\u0026gt; dev wweb \u0026lt;/body\u0026gt; node3 | CHANGED | rc=0 \u0026gt;\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a development webserver, have fun!\u0026lt;/h1\u0026gt; dev wweb \u0026lt;/body\u0026gt; Note the warning in the first line about not to use curl via the command module since there are better modules right within Ansible. We will come back to that in the next part.\nAdd Survey   Add a survey to the Template to allow changing the variables dev_content and prod_content.\n  Add permissions to the Team Web Content so the Template Create Web Content can be executed by wweb.\n  Run the survey as user wweb.\n  Check the results again from your code-server terminal. Since we got a warning last time using curl via the command module, this time we will use the dedicated uri module. As arguments it needs the actual URL and a flag to output the body in the results.\n[student\u0026lt;N\u0026gt;ansible ~]$ ansible web -m uri -a \u0026#34;url=http://{{ ansible_host }} return_content=yes\u0026#34; node3 | SUCCESS =\u0026gt; { \u0026#34;accept_ranges\u0026#34;: \u0026#34;bytes\u0026#34;, \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;connection\u0026#34;: \u0026#34;close\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;\u0026lt;body\u0026gt;\\n\u0026lt;h1\u0026gt;This is a development webserver, have fun!\u0026lt;/h1\u0026gt;\\nwerners dev content\\n\u0026lt;/body\u0026gt;\\n\u0026#34;, \u0026#34;content_length\u0026#34;: \u0026#34;87\u0026#34;, \u0026#34;content_type\u0026#34;: \u0026#34;text/html; charset=UTF-8\u0026#34;, \u0026#34;cookies\u0026#34;: {}, \u0026#34;cookies_string\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;Tue, 29 Oct 2019 11:14:24 GMT\u0026#34;, \u0026#34;elapsed\u0026#34;: 0, \u0026#34;etag\u0026#34;: \u0026#34;\\\u0026#34;57-5960ab74fc401\\\u0026#34;\u0026#34;, \u0026#34;last_modified\u0026#34;: \u0026#34;Tue, 29 Oct 2019 11:14:12 GMT\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;OK (87 bytes)\u0026#34;, \u0026#34;redirected\u0026#34;: false, \u0026#34;server\u0026#34;: \u0026#34;Apache/2.4.6 (Red Hat Enterprise Linux)\u0026#34;, \u0026#34;status\u0026#34;: 200, \u0026#34;url\u0026#34;: \u0026#34;http://18.205.236.208\u0026#34; } [...] Solution Solution NOT below   You have to figure this one out by yourself! ;-)\n  You have done all the required configuration steps in the lab already. If unsure, just refer back to the respective chapters.\nThe End Congratulations, you finished your labs! We hope you enjoyed your first encounter with Ansible Tower as much as we enjoyed creating the labs.\n"
},
{
	"uri": "https://lj020326.github.io/ansible-getting-started/7-bonus/",
	"title": "Bonus Labs",
	"tags": [],
	"description": "",
	"content": "You have finished the lab already. But it doesn’t have to end here. We prepared some slightly more advanced bonus labs for you to follow through if you like. So if you are done with the labs and still have some time, here are some more labs for you:\nBonus Lab: Ad Hoc Commands Create a new user testuser on node1 and node3 with a comment using an ad hoc command, make sure that it is not created on node2!\n  Find the parameters for the appropriate module using ansible-doc user (leave with q)\n  Use an Ansible ad hoc command to create the user with the comment Test D User\n  Use the command module with the proper invocation to find the userid\n  Delete the user and check it has been deleted\n  Remember privilege escalation…​\n Click here for Solution   Your commands could look like these:\n[student@ansible-1 ansible-files]$ ansible-doc -l | grep -i user [student@ansible-1 ansible-files]$ ansible-doc user [student@ansible-1 ansible-files]$ ansible node1,node3 -m user -a \u0026#34;name=testuser comment=\u0026#39;Test D User\u0026#39;\u0026#34; -b [student@ansible-1 ansible-files]$ ansible node1,node3 -m command -a \u0026#34; id testuser\u0026#34; -b [student@ansible-1 ansible-files]$ ansible node2 -m command -a \u0026#34; id testuser\u0026#34; -b [student@ansible-1 ansible-files]$ ansible node1,node3 -m user -a \u0026#34;name=testuser state=absent remove=yes\u0026#34; -b [student@ansible-1 ansible-files]$ ansible web -m command -a \u0026#34; id testuser\u0026#34; -b \n  Bonus Lab: Templates and Variables You have learned the basics about Ansible templates, variables and handlers. Let’s combine all of these.\nInstead of editing and copying httpd.conf why don’t you just define a variable for the listen port and use it in a template? Here is your job:\n  Define a variable listen_port for the web group with the value 8080 and another for node2 with the value 80 using the proper files.\n  Copy the httpd.conf file into the template httpd.conf.j2 that uses the listen_port variable instead of the hard-coded port number.\n  Write a Playbook that deploys the template and restarts Apache on changes using a handler.\n  Run the Playbook and test the result using curl.\n  Remember the group_vars and host_vars directories? If not, refer to the chapter Using Variables.\n Define the variables: Add this line to group_vars/web:\nlisten_port: 8080 Add this line to host_vars/node2:\nlisten_port: 80 Prepare the template:   Copy httpd.conf to httpd.conf.j2\n  Edit the Listen directive in httpd.conf.j2 to make it look like this:\n  [...] Listen {{ listen_port }} [...] Create the Playbook Create a playbook called apache_config_tpl.yml:\n--- - name: Apache httpd.conf hosts: web become: yes tasks: - name: Create Apache configuration file from template template: src: httpd.conf.j2 dest: /etc/httpd/conf/httpd.conf notify: - restart apache handlers: - name: restart apache service: name: httpd state: restarted Run and test First run the playbook itself, then run curl against node1 with port 8080 and node2 with port 80.\n[student@ansible-1 ansible-files]$ ansible-playbook apache_config_tpl.yml [...] [student@ansible-1 ansible-files]$ curl http://18.195.235.231:8080 \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a development webserver, have fun!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; [student@ansible-1 ansible-files]$ curl http://35.156.28.209:80 \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a production webserver, take care!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; The End Congratulations, you finished your labs! We hope you enjoyed your first encounter with Ansible as much as we enjoyed creating the labs.\n"
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/8-isolated-nodes/",
	"title": "Isolated Nodes",
	"tags": [],
	"description": "",
	"content": "Ansible is used to manage complex infrastructures with machines and networks living in multiple separate datacenters, servers behind firewalls or in cloud VPCs and remote locations only reachable over unstable links which may not survive the length of a job run. In cases like these it’s often better to run automation local to the nodes.\nTo address such requirements, Tower provides Isolated Nodes:\n  Isolated Nodes don’t have a full installation of Tower, but a minimal set of utilities used to run jobs.\n  Isolated Nodes can be deployed behind a firewall/VPC or in a remote datacenter, only ingress SSH traffic from a controller instance to the isolated instances is required.\n  When a job is run that targets things managed by an isolated node, the job and its environment will be pushed to the isolated node over SSH.\n  Periodically, the master Ansible Tower cluster will poll the isolated node for status on the job.\n  When the job finishes, the job status will be updated in Ansible Tower.\n  Prepare the Isolated Node Because of the setup of this lab environment, before we configure the isolated node we need to do some preparation. As your student user in your VSCode terminal, execute the following steps:\n[student@ansible-1 ~]$ scp /etc/hosts isonode: [student@ansible-1 ~]$ ssh isonode sudo mv /home/ec2-user/hosts /etc/ Setting Up Isolated Nodes Isolated nodes are defined in the installer inventory file and setup by the Ansible Tower installer. Isolated nodes make up their own instance groups that are specified in the inventory file prefixed with isolated_group_. In the isolated instance group model, controller instances interact with isolated instances via a series of Ansible playbooks over SSH.\nSo for the fun of it, let’s set one up.\nFirst have a look at the Tower installer inventory file that was used for lab setup. In your VSCode terminal on your Tower node 1 change into the Ansible installer directory and do the following:\n[student@ansible-1 ~]$ cd /tmp/tower_install/ [student@ansible-1 tower_install]$ cat inventory [tower] ansible-1 ansible-2 ansible-3 [database] ansible-4 [...]  You can see we have the tower base group and one for the database node. For the isolated node we will define a new isolated_group_ named dmz with one entirely new node, called isonode which we’ll use to manage other hosts in the remote location.\nThe Ansible installer files in /tmp/tower_install/ are owned by root, but your code-server/VSCode instance is running as your student\u0026lt;N\u0026gt; user. To be able to edit the inventory file, you have to change the file permissions.\n To edit the inventory file in VSCode editor change the permissions (don\u0026rsquo;t do 666 in real life\u0026hellip; ;-)):\n[student@ansible-1 ~]$ sudo -i [ansible-1 ~]# chmod 666 /tmp/tower_install/inventory [ansible-1 ~]# exit Then do File -\u0026gt; Open File in VSCode, navigate to /tmp/tower_install/inventory file and open it. Add the isolated node to the inventory to look like this:\n[tower] ansible-1 ansible-2 ansible-3 [isolated_group_dmz] isonode [isolated_group_dmz:vars] controller=tower [database] ansible-4 [...]  Only add the isolated_group settings, don\u0026rsquo;t change the other groups and settings!\n Each isolated group must have a controller variable set. This variable points to the instance group that manages tasks that are sent to the isolated node. That instance group will be responsible for starting and monitoring jobs on the isolated node. In this case, we’re using the main tower instance group to manage this isolated group.\n After editing the inventory, start the installer in the VSCode terminal to make the desired changes:\n[student@ansible-1 ~]$ sudo -i [ansible-1 ~]# cd /tmp/tower_install/ [ansible-1 tower_install]# ./setup.sh  The setup.sh script will take a couple of minutes to finish execution.\n Sit down and watch the tasks flying by\u0026hellip;\nVerify Isolated Nodes After the installer has finished isolated groups can be listed in the same way like instance groups and Ansible Tower cluster configuration. So the methods listed above discussing instance groups also apply to isolated nodes. For example, using awx as the student user:\n[student@ansible-1 ~]$ awx -f human instance_group list id name == ===== 1 tower 2 dev 3 prod 4 dmz You can see your dmz isolated group has been setup. Like other instance groups, isolated node groups can be assigned at the level of an organization, an inventory, or an individual job template.\nCreate Isolated Node specific Inventory To actually do something in the remote location served by the isolated node we need a managed host. Let’s assume we have a setup with one host in our DMZ, and we want to manage it siloed off from the rest of the infrastructure. The isolated node we configured above is located in the same location and is able to connect to the managed host(s).\nFor this you have to create a new inventory in your Tower cluster. You can do this with awx like we did in the beginning, or you use the web UI. Why not use the web UI for a change?\nIn the Tower web UI under RESOURCES, click Inventories:\n  Click the button to add a new inventory\n  NAME: Remote Inventory\n  ORGANIZATION: Default\n  INSTANCE GROUPS: Pick the instance group you created in the last step, dmz\n  Click SAVE\n    Now you can add managed hosts, the HOSTS button is active now. Click it to access the hosts overview. There are no hosts right now, so let’s add one:\n  Click the button to add a new host\n  NAME: remotenode\n  Click SAVE\n  Create Template for Isolated Node Next we need to assign a job template to the node. Since the node is in a DMZ, we certainly have to ensure their compliance. Thus we are going to make sure that they are following our CIS guidelines - and will set up a template executing the CIS playbook on them.\nGo to Templates in the RESOURCES section of the menu, click the button and choose Job Template.\n  NAME: Remote CIS Compliance\n  JOB TYPE: Run\n  INVENTORY: Remote Inventory\n  PROJECT: Apache\n  PLAYBOOK: cis.yml\n  CREDENTIAL: Example Credentials\n  We need to run the tasks as root so check Enable privilege escalation\n  Click SAVE\n  We could have set the instance group to dmz also at the job template level, but this would have been here unnecessary work, as we already did set it at the inventory level.\n Next, launch the template:\n  In the Templates view launch the Remote CIS Compliance job by clicking the rocket icon.\n  Wait until the job has finished.\n  Verify Results Last but not least, let’s check that the job was indeed executed by the isolated node isonode:\n  Go to Instance Groups in the ADMINISTRATION section of the web UI\n  Click on the dmz group.\n  Click on the jobs button at the top to see the executed job.\n  "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/9-advanced-inventories/",
	"title": "Advanced Inventories",
	"tags": [],
	"description": "",
	"content": "In Ansible and Ansible Tower, as you know, everything starts with an inventory. There are a several methods how inventories can be created, starting from simple static definitions over importing inventory files to dynamic and smart inventories.\nIn real life it’s very common to deal with external dynamic inventory sources (think cloud…). In this chapter we’ll introduce you to building dynamic inventories using custom scripts. Another great feature of Tower to deal with inventories is the Smart Inventory feature which you’ll do a lab on as well.\nDynamic Inventories Quite often just using static inventories will not be enough. You might be dealing with ever-changing cloud environments or you have to get your managed systems from a CMDB or other sources of truth.\nTower includes built-in support for syncing dynamic inventory from cloud sources such as Amazon AWS, Google Compute Engine, among others. Tower also offers the ability to use custom scripts to pull from your own inventory source.\nIn this chapter you’ll get started with dynamic inventories in Tower. Aside from the build-in sources you can write inventory scripts in any programming/scripting language that you have installed on the Tower machine. To keep it easy we’ll use a most simple custom inventory script using… Bash! Yes!\nDon’t get this wrong… we’ve chosen to use Bash to make it as simple as possible to show the concepts behind dynamic and custom inventories. Usually you’d use Python or some other scripting/programming language.\n The Inventory Source First you need a source. In real life this would be your cloud provider, your CMDB or what not. For the sake of this lab we put a simple file into a Github repository.\nUse curl to query your external inventory source:\n[student@ansible-1 ~]$ curl https://raw.githubusercontent.com/lj020326/ansible-labs-playbooks/master/inventory_list { \u0026#34;dyngroup\u0026#34;:{ \u0026#34;hosts\u0026#34;:[ \u0026#34;cloud1.cloud.example.com\u0026#34;, \u0026#34;cloud2.cloud.example.com\u0026#34; ], \u0026#34;vars\u0026#34;:{ \u0026#34;var1\u0026#34;: true } }, \u0026#34;_meta\u0026#34;:{ \u0026#34;hostvars\u0026#34;:{ \u0026#34;cloud1.cloud.example.com\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;web\u0026#34; }, \u0026#34;cloud2.cloud.example.com\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;database\u0026#34; } } } } Well, this is handy, the output is already configured as JSON like Ansible would expect… ;-)\nOkay, seriously, in real life your script would likely get some information from your source system, format it as JSON and return the data to Tower.\n The Custom Inventory Script An inventory script has to follow some conventions. It must accept the \u0026ndash;list and \u0026ndash;host \u0026lt;hostname\u0026gt; arguments. When it is called with \u0026ndash;list, the script must output a JSON-encoded data containing all groups and hosts to be managed. When called with \u0026ndash;host \u0026lt;hostname\u0026gt; it must return an JSON-formatted hash or dictionary of host variables (can be empty).\nAs looping over all hosts and calling the script with \u0026ndash;host can be pretty slow, it is possible to return a top level element called \u0026ldquo;_meta\u0026rdquo; with all of the host variables in one script run. And this is what we’ll do. So this is our custom inventory script:\n#!/bin/bash  if [ \u0026#34;$1\u0026#34; == \u0026#34;--list\u0026#34; ] ; then curl https://raw.githubusercontent.com/lj020326/ansible-labs-playbooks/master/inventory_list elif [ \u0026#34;$1\u0026#34; == \u0026#34;--host\u0026#34; ]; then echo \u0026#39;{\u0026#34;_meta\u0026#34;: {\u0026#34;hostvars\u0026#34;: {}}}\u0026#39; else echo \u0026#34;{ }\u0026#34; fi What it basically does is to return the data collected by curl when called with \u0026ndash;list and as the data includes _meta information about the host variables Ansible will not call it with \u0026ndash;host. The curl command is of course the place where your script would get data by whatever means, format it as proper JSON and return it.\nBut before we integrate the custom inventory script into our Tower cluster, it’s a good idea to test it on the command line first:\n Bring up your VSCode terminal Create the file dyninv.sh with the content shown above (use VI or the VSCode editor) Make the script executable:  [student@ansible-1 ~]$ chmod +x dyninv.sh  Execute it:  [student@ansible-1 ~]$ ./dyninv.sh --list { \u0026#34;dyngroup\u0026#34;:{ \u0026#34;hosts\u0026#34;:[ \u0026#34;cloud1.cloud.example.com\u0026#34;, \u0026#34;cloud2.cloud.example.com\u0026#34; ], \u0026#34;vars\u0026#34;:{ \u0026#34;var1\u0026#34;: true } }, \u0026#34;_meta\u0026#34;:{ \u0026#34;hostvars\u0026#34;:{ \u0026#34;cloud1.cloud.example.com\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;web\u0026#34; }, \u0026#34;cloud2.cloud.example.com\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;database\u0026#34; } } } } The script should output the JSON-formatted output shown above.\nAs simple as it gets, right? More information can be found how to develop dynamic inventories.\nSo now you have a source of (slightly static) dynamic inventory data (talk about oxymoron…) and a script to fetch and pass it to Tower. Now you need to get this into Tower.\nIntegrate into Tower The first step is to add the inventory script to Tower:\n  In the web UI, open RESOURCES→Inventory Scripts.\n  To create a new custom inventory script, click the button.\n  Fill in the needed data:\n  NAME: Cloud Inventory Script\n  Copy the Bash script from above and paste it into the CUSTOM SCRIPT field\n    Click SAVE\n  Finally the new inventory script can be used in an actual Inventory.\n  Go to RESOURCES→Inventories\n  Click the button and choose Inventory.\n  NAME: Cloud Inventory\n  Click SAVE\n  The SOURCES button on top becomes active now, click it\n  Click the to add a new source\n  NAME: Cloud Custom Script\n  From the SOURCE drop-down choose Custom Script\n  Now the dialog for the source opens, your custom script Cloud Inventory Script should already be selected in the CUSTOM INVENTORY SCRIPT.\n  Under UPDATE OPTIONS check Overwrite and Overwrite Variables\n  Click SAVE\n  To sync your new source into the inventory:\n  Open the Cloud Inventory again\n  Click the SOURCES button\n  To the right click the circular arrow to start the sync process for your custom source.\n  After the sync has finished click the HOSTS button (the top one).\n  You should now see a list of hosts according to what you got from the curl command above. Click the hosts to make sure the host variables are there, too.\nWhat is the take-away? Using this simple example you have:\n  Created a script to query an inventory source\n  Integrated the script into Tower\n  Populated an inventory using the custom script\n  Smart Inventories You will most likely have inventories from different sources in your Tower installation. Maybe you have a local CMDB, your virtualization management and your public cloud provider to query for managed systems. Imagine you now want to run automation jobs across these inventories on hosts matching certain search criteria.\nThis is where Smart Inventory comes in. A Smart Inventory is a collection of hosts defined by a stored search. Search criteria can be host attributes (like groups) or facts (such as installed software, services, hardware or whatever information Ansible pulls). A Smart Inventory can be viewed like a standard inventory and used for job runs.\nThe base rules of a search are:\n  A search typically consists of a field (left-hand side) and a value (right-hand side)\n  A colon separates the field that you want to search from the value\n  A search string without a colon is treated as a simple string\n  A Simple Smart Inventory Let’s start with a simple string example. In your Tower web UI, open the RESOURCES→Inventories view. Then click the button and choose to create a new Smart Inventory. In the next view:\n  NAME: Smart Inventory Simple\n  Click the magnifying glass icon next to SMART HOST FILTER\n  A window DYNAMIC HOSTS opens, here you define the search query\n  To start with you can just use simple search terms. Try cloud or example.com as search terms and see what you get after hitting ENTER.\nSearch terms are automatically saved so make sure to hit CLEAR ALL to clear the saved search when testing expressions.\n Or what about searching by inventory groups? In the SEARCH field enter groups.name:dyngroup. After hitting ENTER the hosts from the dynamic inventory exercise should show up.\nWhen your search returns the expected results, hit SAVE for the DYNAMIC HOSTS window and again for the Smart Inventory. Now your Smart Inventory is usable for executing job templates!\nYou may press the KEY button to get a feeling along which fields you can search. Browsing through the API becomes necessary to understand which related fields have which attributes (e.g. name for groups).\n Build Smart Inventories with Facts As you know Ansible can collect facts from managed hosts to be used in Playbooks. But before Ansible Tower 3.2 facts where only kept during a Playbook run. Ansible Tower 3.2 introduced an integrated fact cache to keep host facts for later usage and better performance. This is how we can use facts in searches for Smart Inventories.\nEnable Fact Caching Fact caching is not enabled by default!\n Fact caching can be enabled for Templates and is not enabled by default. So first we have to enable it. Check node1 and node2 have no facts stored:\n  In RESOURCES→Inventories open the Example Inventory and click the HOSTS button.\n  Now inspect both hosts by opening the host details and clicking the FACTS button at the top.\n  For both hosts the FACTS field should be empty\n  Now enable fact caching for the Install Apache template:\n  In RESOURCES→Templates open the Install Apache template.\n  Check the ENABLE FACT CACHE tick box and click SAVE\n  To gather and save the facts you have to run the job template.\n In the Templates list start Install Apache by clicking the rocket icon  Now enable fact caching for the Remote CIS Compliance template and run it, too. This way we’ll get cached facts for the remote DMZ host.\nAfter you run the templates go back to the host details like you did above and check the FACTS fields for\n  node1 and node2 (from the Example Inventory)\n  remotenode (from the Remote Inventory).\n  The hosts facts should now be populated with a lot of information.\nUse Facts in Smart Inventory Searches Now that we got the facts for the hosts in the facts cache, we can use facts in our searches.\n  Create a new Smart Inventory named Smart Inventory Facts\n  Open the SMART HOST FILTER window to enter the search\n  To search for facts the search field (left side of a search query) has to start with ansible_facts. followed by the fact. The value is separated by a colon on the right side.\nNo blank between field and value is allowed!\n So what could we search for… start to look at the facts of a host. As all hosts are Red Hat, searching for the fact ansible_distribution:RedHat won’t be too exciting. Ah, what the heck, just try it:\n  Put ansible_facts.ansible_distribution:RedHat in the search field\n  Run the search by hitting ENTER\n  There should be no surprises: All hosts you have run a fact-caching enabled template on should show up.\nNested Facts A small hint: If a fact is deeper in the structure like this:\nansible_eth0: active: true  The search string would look like this: ansible_facts.ansible_eth0.active:true\nChallenge Lab: Smart Inventory with Facts So a small challenge: Find out if all hosts have the SElinux mode set to \u0026ldquo;enforcing\u0026rdquo;.\n  Find the fact to use by looking at the host facts\n  Create a Smart Inventory\n  Create the proper search string\n  Save the new Smart Inventory\n  Click here for Solution   The search string to use is: ansible_facts.ansible_selinux.mode:enforcing. It should return all hosts.\n  And to make this a bit more fun:\n SSH into one of your hosts (say node2) as ec2-user from your VSCode terminal and set SELinux to permissive:  [student@ansible-1 ~]$ ssh ec2-user@node2 [ec2-user@node2 ~]$ sudo setenforce 0   Run the Install Apache template again to update the facts.\n  Make sure the host is not showing up in the Smart inventory you just created anymore.\n  "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/10-structured-content/",
	"title": "Well Structured Content Repositories",
	"tags": [],
	"description": "",
	"content": "OPTIONAL EXERCISE It’s a common part of the learning curve for Ansible and Ansible Tower: At some point you will have written so many playbooks that a need for structure comes up. Where to put the Playbooks, what about the Templates, Files and so on.\nThe main recommendations are:\n  Put your content in a version control system like Git or SVN. This comes naturally since Ansible code is usually in text form anyway, and thus can be managed easily.\n  Group your code by logical units, called \u0026ldquo;roles\u0026rdquo; in Ansible.\n Example: have all code, config templates and files for the apache web server in one role, and all code, configuration and sql statements for the database in another role. That way the code becomes much better to read and handle, and roles can be made re-usable and shared between projects, teams or with the global community.    Of course, what structure works best in the end depends on the individual requirements, but we will highlight some common ground rules which apply to almost all use cases.\nThe first recommendation is to separate specific code from reusable/generic code from data:\n  specific code: Playbooks and their direct dependencies which are not shared outside the realm of the project or team.\n  generic code: All content that will be used across multiple projects.\n  data: This is mostly the inventory or the inventory scripts and the corresponding variables for hosts and groups. In many use cases it is advisable to have a dedicated inventory for each life-cycle environment.\n  Data content files can be in the same Git repository, each in its own directory (e.g. dev, test, qa, prod). Alternatively, for example in larger environments or with dedicated teams per environment there can be one Git repository for each environment. We recommend to put special focus on splitting out host and group data.\n Be careful to not have separate code repositories for each environment. It would go against the purpose of testing the same code as you push it through your life-cycle, only varying the data / inventory. If you have difficulties to keep the same code throughout all your environments we recommend to re-think the structure of our code and what you put into your inventory.\n Example repository So, let’s get started with an example. The content and repo-structure in this lab is mostly aligned to the Ansible best practices and is explained in more detail there (we\u0026rsquo;ve had to simplify a bit for the lab).\nSince we want to store all content in a repository, we have to create a simplistic Git server on our control host. In a more typical environment, you would work with GitLab, Gitea, or any other commercial Git server.\n[student@ansible-1 ~]$ wget https://raw.githubusercontent.com/ansible-labs-summit-crew/structured-content/master/simple_git.yml [student@ansible-1 ~]$ ansible-playbook simple_git.yml Next we will clone the repository on the control host. To enable you to work with git on the command line the SSH key for user ec2-user was already added to the Git user git. Next, clone the repository on the control machine:\n[student@ansible-1 ~]$ git clone git@ansible-1:projects/structured-content.git # Message \u0026quot;warning: You appear to have cloned an empty repository.\u0026quot; is OK and can be ignored [student@ansible-1 ~]$ git config --global push.default simple [student@ansible-1 ~]$ git config --global user.name \u0026quot;Your Name\u0026quot; [student@ansible-1 ~]$ git config --global user.email you@example.com [student@ansible-1 ~]$ cd structured-content/  The repository is currently empty. The three config commands are just there to avoid useless warnings from Git.\n You are now going to add some default directories and files:\n[student@ansible-1 structured-content]$ touch {staging,production}  This command creates two inventory files: in this case we have different stages with different hosts which we keep them in separate inventory files. Note that those files are right now still empty and need to be filled with content to work properly.\nIn the current setup we have two instances. Let’s assume that node1 is part of the staging environment, and node2 is part of the production environment. To reflect that in the inventory files, edit the two empty inventory files to look like this:\n[student@ansible-1 structured-content]$ cat staging [staging] node1 [student@ansible-1 structured-content]$ cat production [production] node2  Next we add some directories:\n  directories for host and group variables\n  A roles directory where the main part of our automation logic will be in.\n  For demonstration purpose we also will add a library directory: it can contain Ansible code related to a project like custom modules, plugins, etc.\n[student@ansible-1 structured-content]$ mkdir -p {group_vars,host_vars,library,roles}\n  Now to the two roles we’ll use in this example. First we’ll create a structure where we’ll add content later. This can easily be achieved with the command ansible-galaxy: it creates role skeletons with all appropriate files, directories and so on already in place.\n[student@ansible-1 structured-content]$ ansible-galaxy init --offline --init-path=roles security [student@ansible-1 structured-content]$ ansible-galaxy init --offline --init-path=roles apache  Even if a good role is generally self-explanatory, it still makes sense to have proper documentation. The right location to document roles is the file meta/main.yml.\n The roles are empty, so we need to add a few tasks to each. In the last chapters we set up an Apache webserver and used some security tasks. Let’s add that code to our roles by editing the two task files:\n[student@ansible-1 structured-content]$ cat roles/apache/tasks/main.yml --- # tasks file for apache - name: latest Apache version installed yum: name: httpd state: latest - name: latest firewalld version installed yum: name: firewalld state: latest - name: firewalld enabled and running service: name: firewalld enabled: true state: started - name: firewalld permits http service firewalld: service: http permanent: true state: enabled immediate: yes - name: Apache enabled and running service: name: httpd enabled: true state: started [student@ansible-1 structured-content]$ cat roles/security/tasks/main.yml --- # tasks file for security - name: \u0026quot;HIGH | RHEL-07-010290 | PATCH | The Red Hat Enterprise Linux operating system must not have accounts configured with blank or null passwords.\u0026quot; replace: dest: \u0026quot;{{ item }}\u0026quot; follow: true regexp: 'nullok ?' with_items: - /etc/pam.d/system-auth - /etc/pam.d/password-auth - name: \u0026quot;MEDIUM | RHEL-07-010210 | PATCH | The Red Hat Enterprise Linux operating system must be configured to use the shadow file to store only encrypted representations of passwords.\u0026quot; lineinfile: dest: /etc/login.defs regexp: ^#?ENCRYPT_METHOD line: \u0026quot;ENCRYPT_METHOD SHA512\u0026quot; - name: \u0026quot;SCORED | 1.1.1.2 | PATCH | Remove freevxfs module\u0026quot; modprobe: name: freevxfs state: absent  We also need to create a playbook to call the roles from. This is often call site.yml, since it keeps the main code for the setup of our environment. Create the file:\n[student@ansible-1 structured-content]$ cat site.yml --- - name: Execute apache and security roles hosts: all roles: - { role: apache } - { role: security }  So we have prepared a basic structure for quite some content - call tree to look at it.\nClick here for Solution   [student@ansible-1 structured-content]$ tree . ├── group_vars ├── host_vars ├── library ├── production ├── roles │ ├── apache │ │ ├── defaults │ │ │ └── main.yml │ │ ├── files │ │ ├── handlers │ │ │ └── main.yml │ │ ├── meta │ │ │ └── main.yml │ │ ├── README.md │ │ ├── tasks │ │ │ └── main.yml │ │ ├── templates │ │ ├── tests │ │ │ ├── inventory │ │ │ └── test.yml │ │ └── vars │ │ └── main.yml │ └── security │ ├── defaults │ │ └── main.yml │ ├── files │ ├── handlers │ │ └── main.yml │ ├── meta │ │ └── main.yml │ ├── README.md │ ├── tasks │ │ └── main.yml │ ├── templates │ ├── tests │ │ ├── inventory │ │ └── test.yml │ └── vars │ └── main.yml ├── site.yml └── staging  In real life, you should remove the unnecessary roles sub-directories to keep the structure easier to understand and maintain.\n   Since we so far created the code only locally on the control host, we need to add it to the repository and push it:\n[student@ansible-1 structured-content]$ git add production roles site.yml staging [student@ansible-1 structured-content]$ git commit -m \u0026#34;Adding inventories and apache security roles\u0026#34; [student@ansible-1 structured-content]$ git push Launch it! From the Command Line The code can now be launched. We start at the command line. Call the playbook site.yml with the appropriate inventory and privilege escalation:\n[student@ansible-1 structured-content]$ ansible-playbook -i staging site.yml -b  Watch how the changes are done to the target machines. Afterwards, we could similarly execute the playbook against the production stage, but we want to keep something for Tower to do, so we just check it:\n[student@ansible-1 structured-content]$ ansible-playbook -i production site.yml -b --list-hosts --list-tasks  Call e.g. curl node1 to get the default page.\nFrom Tower To configure and use this repository as a Source Control Management (SCM) system in Tower you have to create credentials again, this time to access the Git repository over SSH. This credential is user/key based, and we need the following awx command (assuming the TOWER_ environment variables are still defined):\n[student@ansible-1 ~]# awx -f human credential create --name \u0026#34;Git Credentials\u0026#34; \\ --organization \u0026#34;Default\u0026#34; \\  --credential_type \u0026#34;Source Control\u0026#34; \\  --inputs \u0026#39;{\u0026#34;username\u0026#34;: \u0026#34;git\u0026#34;, \u0026#34;ssh_key_data\u0026#34;: \u0026#34;@~/.ssh/aws-private.pem\u0026#34;}\u0026#39; The new repository needs to be added as project. Feel free to use the web UI or use awx like shown below.\n[student@ansible-1 ~]# awx -f human project create --name \u0026#34;Structured Content Repository\u0026#34; \\ --organization Default \\  --scm_type git \\  --scm_url git@ansible-1:projects/structured-content.git \\  --scm_clean 1 \\  --scm_update_on_launch 1 \\  --credential \u0026#34;Git Credentials\u0026#34; Now you’ve created the Project in Tower. Earlier on the command line you’ve setup a staged environment by creating and using two different inventory files. But how can we get the same setup in Tower? We use another way to define Inventories! It is possible to use inventory files provided in a SCM repository as an inventory source. This way we can use the inventory files we keep in Git.\nIn your Tower web UI, open the RESOURCES→Inventories view. Then click the button and choose to create a new Inventory. In the next view:\n  NAME: Structured Content Inventory\n  Click SAVE\n  Click the button SOURCES which is now active at the top\n  Click the button (the top right one)\n  NAME: Production\n  SOURCE: Pick Sourced from a Project\n  PROJECT: Structured Content Repository\n  In the INVENTORY FILE drop down menu, pick production\n  Click the green SAVE button\n  And now for the staging inventory:\n  Down below in the view, click the button again\n  In the next view, add as NAME: Staging\n  SOURCE: Pick Sourced from a Project\n  PROJECT: Structured Content Repository\n  In the INVENTORY FILE drop down menu, pick staging\n  Click the green SAVE button\n  In the screen below, click the sync button for both sources, or SYNC ALL once so that the cloud icon on the left site next to the name of each inventory turns green.\n  To make sure that the project based inventory worked, click on the HOSTS button of the Inventory and make sure the two hosts are listed and tagged with the respective stages as RELATED GROUPS.\nNow create a template to execute the site.yml against both stages at the same time and associate the credentials.\nPlease note that in a real world use case you might want to have different templates to address the different stages separably.\n[student@ansible-1 ~]# awx -f human job_template create --name \u0026#34;Structured Content Execution\u0026#34; \\ --job_type run --inventory \u0026#34;Structured Content Inventory\u0026#34; \\  --project \u0026#34;Structured Content Repository\u0026#34; \\  --playbook \u0026#34;site.yml\u0026#34; \\  --become_enabled 1 [student@ansible-1 ~]# awx -f human job_template associate --name \u0026#34;Structured Content Execution\u0026#34; \\ --credential \u0026#34;Example Credentials\u0026#34;  Now in the Tower web UI go to RESOURCES→Templates, launch the job template Structured Content Execution and watch the results.\nAdding External Roles So far we have only worked with content inside a single repository. While this drastically reduces complexity already, the largest benefit is in sharing roles among multiple teams or departments and keeping them in a central place. In this section we will show how to reference shared roles in your code and execute them together on your behalf.\nIn enterprise environments it is common to share roles via internal git repositories, often one git repository per role. If a role might be interesting and re-used by the world wide Ansible community, they can be shared on our central platform Ansible Galaxy. The advantage of Ansible Galaxy is that it features basic automatic testing and community ratings to give the interested users an idea of the quality and reusability of a role.\nTo use external roles in a project, they need to be referenced in a file called roles/requirements.yml, for example like this:\n# Import directly from Galaxy - src: geerlingguy.nginx # Import from a local Git repository - src: http://control.example.com/gitea/git/external-role.git version: master name: external-role_locally The requirements.yml needs to be read - either on the command line by invoking ansible-galaxy, or automatically by Ansible Tower during project check outs. In both cases the file is read, and the roles are checked out and stored locally, and the roles can be called in playbooks. The advantage of Tower here is that it takes care of all that - including authorization to the Git repo, finding a proper place to store the role, updating it when needed and so on.\nIn this example, we will include a role which ships a simple index.html file as template and reloads the apache web server. The role is already shared in GitHub at https://github.com/ansible-labs-summit-crew/shared-apache-role.\nTo include it with the existing structured content, first we have to create a file called roles/requirements.yml and reference the role there:\nMake sure you work as user student\u0026lt;N\u0026gt;\n Let\u0026rsquo;s create a roles/requirements.yml file:\n[student@ansible-1 structured-content]$ cat roles/requirements.yml - src: https://github.com/ansible-labs-summit-crew/shared-apache-role.git scm: git version: master  In a production environment you may want to change the version to a fixed version or tag, to make sure that only tested and verified code is checked out and used. But this strongly depends on how you develop your code and which branching model you use.\n Next, we reference the role itself in our playbook. Change the site.yml Playbook to look like this:\n[student@ansible-1 structured-content]$ cat site.yml --- - name: Execute apache and security roles hosts: all roles: - { role: apache} - { role: security } - { role: shared-apache-role } Because Tower uses your Git repo, you’ve to add, commit and push the changes:\n[student@ansible-1 structured-content]$ git add site.yml roles/ [student@ansible-1 structured-content]$ git commit -m \u0026#34;Add roles/requirements.yml referencing shared role\u0026#34; [student@ansible-1 structured-content]$ git push Launch in Tower Just in case, make sure to update the Project in Tower: in the menu at RESOURCES, pick Projects, and click on the sync button next to Structured Content Repository.\nAfterwards, go to RESOURCES→Templates and launch the Structured Content Execution job template. As you will see in the job output, the external role is called just the way the other roles are called:\nTASK [shared-apache-role : deploy content] ************************************* changed: [node2] changed: [node1]  Validate again with curl the result and you are done!\nThis was quite something to follow through, so let’s review:\n  You successfully integrated a shared role provided from a central source into your automation code.\n  This way, you can limit your automation code to things really relevant and individual to the task and your environment, while everything generic is consumed from a shared resource.\n  "
},
{
	"uri": "https://lj020326.github.io/ansible-tower-advanced/11-rest-api/",
	"title": "Discovering the Tower API",
	"tags": [],
	"description": "",
	"content": "OPTIONAL EXERCISE You have used the Tower API a couple of times in this lab already. In this chapter we’ll describe two ways to discover the Tower API if you need to dive in deeper. While the principles of the Tower API are documented and there is an API reference guide, it’s often more efficient to just browse and discover the API.\nBrowsing and Using the Tower API interactively The Tower API is browsable, which means you can just click your way through it:\n  Go to the Tower UI in your browser and make sure you’re logged in as admin.\n  Replace the end of the URL with /api e.g. https://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com/api\n  There is currently only one API valid, so while in /api/v2:\n  you see a list of clickable object types\n  on the right upper side, there is a button OPTIONS which tells you what you can do with the current object in terms of API.\n  next to it there is a GET button which allows you to choose between getting the (raw or not) JSON output or the API format, which you’re currently admiring by default.\n    Click on the /api/v2/users/ link and discover some more features:\n  There is a list of all objects of the given type\n  Each individual object can be reached using the url field (\u0026ldquo;url\u0026rdquo;: \u0026ldquo;/api/v2/users/1/\u0026rdquo;,)\n  Most objects have a related field, which allows you to jump from object to object\n  At the bottom of the page, there is a new field which allows you to post a new object, so let’s do this and create a new user name John Smith (user name doesn’t matter)\n    Click here for Solution   The JSON should roughly look like this:\n{ \u0026#34;username\u0026#34;: \u0026#34;jsmith\u0026#34;, \u0026#34;first_name\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;Smith\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;jsmith@example.com\u0026#34;, \u0026#34;is_superuser\u0026#34;: false, \u0026#34;is_system_auditor\u0026#34;: false, \u0026#34;password\u0026#34;: \u0026#34;redhat\u0026#34; } and the result should be a 201 telling you about your success. You can login with the password and see that you see… nothing, because you have no rights.\n  Now log in again as admin and go back to the list of users: https://student\u0026lt;N\u0026gt;.\u0026lt;LABID\u0026gt;.open.redhat.com/api/v2/users/\n  Click on the url field of your new friend John Smith and notice a few more things:\n  There is a red DELETE button at the top right level. Guess for what?\n  At the bottom of the page, the dialog shows PUT and PATCH buttons.\n    So why not patch the user to be named \u0026ldquo;Johnny\u0026rdquo; instead of \u0026ldquo;John\u0026rdquo;?\nClick here for Solution   Add this to the CONTENT field:\n{ \u0026#34;first_name\u0026#34;: \u0026#34;Johnny\u0026#34; } And press the PATCH button.\n  Now try to PUT the last_name \u0026ldquo;Smithy\u0026rdquo; using the same approach. What happens?\nClick here for Solution   Enter this into the CONTENT field and press PUT:\n{ \u0026#34;last_name\u0026#34;: \u0026#34;Smithy\u0026#34; } This will fail. In the case of PUT you need to enter all mandatory fields, even if you don’t want to modify them:\n{ \u0026#34;username\u0026#34;: \u0026#34;jsmith\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;Smithy\u0026#34; } \n  When you’re done press the red DELETE button and remove Johnny Smithy.\n"
},
{
	"uri": "https://lj020326.github.io/vscode-intro/",
	"title": "Visual Studio Code - Introduction",
	"tags": [],
	"description": "",
	"content": "To make it easier for you to perform the tasks described in this workshop, we provide an Visual Studio Code Server for you. This web based IDE allows you to write and edit your Ansible Playbooks and execute command with the built-in Terminal. This part of the Workshop documentation will give you a very quick introduction.\nTested platforms There are probably thousands of combinations of Operating Systems and Web Browsers, and we couldn\u0026rsquo;t test them all. We noticed it works best with Google Chrome (or Chromium) on Linux, Windows or Mac. We ran into issues with Copy \u0026amp; Paste with Firefox and Edge on Windows 10. There might be other issues with other combinations, which is why we recommend to use Chrome/Chromium if you run into problems.\nHow to login Each students has it\u0026rsquo;s dedicated lab environment. This also means you have your dedicated instance of Visual Studio Code Server. The URL to open the Web Interface is:\nhttps://student\u0026lt;N\u0026gt;-code.\u0026lt;LABID\u0026gt;.open.redhat.com  Replace \u0026lt;N\u0026gt; with your student number and \u0026lt;LABID\u0026gt;. You will find your LABID in the invite to this event. If you don\u0026rsquo;t know your LABID, ask your instructor.\nAfter opening the URL, you will see a dialog asking for your password. The password was provided to you in the Lab instructions or the invite to this event.\nIf the password was entered correctly, you will see a web page like this:\nUI Basics On the very left you will see a column of Icons to switch the UI into different modes. During this workshop you will only need the Explorer mode indicated by the two paper icon.\nOn the upper right you should see a large window with a VS Code Welcome message. When you will start working with files, this will show the file you are working on.\nFinally in the lower right you can enable a Terminal session. If you can\u0026rsquo;t see the terminal view, click on Terminal and New Terminal in the menu navigation on the top.\nAs usual, you have a menu bar on the top and you can resize the three parts of the UI by moving the dividers.\nHow to use the Terminal You can execute commands on the Linux command line by using the terminal mode. It\u0026rsquo;s usually shown on the lower right part of the UI. If you can\u0026rsquo;t see the terminal view, click on Terminal and New Terminal in the menu navigation on the top.\nThe terminal is running on your \u0026ldquo;control node\u0026rdquo; or \u0026ldquo;ansible\u0026rdquo; node - this is how we call this instance in the Workshop Guide.\nIt\u0026rsquo;s a fully functional terminal with all the features you would expect from Linux. So, yes, you can break and destroy your instance if you try hard enough.\nWe noticed issues with Copy \u0026amp; Paste. On Linux the best way to paste text is to click the middle mouse button. On Windows 10 in our testing it only worked with Chrome and not with Firefox nor Edge.\n How to create and edit files There are several tasks in the workshop where you will be asked to create and edit files. You can create new files easily by clicking on File, New File. You can also save your files. Pay attention to the lab instructions since you are working in different directories during your lab exercises.\nBy clicking on the Explorer Mode icon (the two paper sheets in the button column on the far left) you can enable and disable a folder tree, which might help you to navigate between different files and folders.\nGotchas Runs best on Chrome Visual Studio Code Server should work well with all modern browsers like Firefox or Chrome. Due to limited resources we did not test all possible combinations. If you run into issues we recommend to use Google Chrome or Chromium.\nIf you don\u0026rsquo;t have Chrome installed, it is available here.\nCopy \u0026amp; Paste and general performance Please also keep in mind that the lab is running in the cloud. Sometimes performance is degraded due to high latency. This became particularly challenging when you try to copy \u0026amp; paste something into the editor window. After pressing Ctrl-V to paste, give a few seconds to respond.\nIn Chrome, you might have to allow paste from clipboard, when you use it the first time.\n"
},
{
	"uri": "https://lj020326.github.io/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Available Labs Ansible Getting Started\nAnsible Tower Getting Started\nAnsible Tower Advanced\nAnsible Collections\nVisual Studio Code - Introduction\n"
},
{
	"uri": "https://lj020326.github.io/ansible-collections/6-automation-hub-and-galaxy/screenshots/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://lj020326.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://lj020326.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]